{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "import json\n",
    "import re\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"GOOGLE_API_KEY\" not in os.environ:\n",
    "    os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter your Google AI API key: \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explaining how AI works is a bit like explaining how the human brain works - it's a complex and evolving field with many different approaches! However, I can break down the fundamental concepts in a way that's hopefully understandable:\n",
      "\n",
      "**At its Core: Learning from Data**\n",
      "\n",
      "AI, at its simplest, is about teaching computers to perform tasks that typically require human intelligence. Instead of being explicitly programmed to do everything, AI systems learn from data.\n",
      "\n",
      "Think of it like teaching a dog a trick. You don't tell the dog *exactly* how to sit (contract these muscles, extend that leg, etc.). Instead, you show them what you want, reward correct behavior, and correct incorrect behavior.  AI works in a similar way, but with data instead of treats.\n",
      "\n",
      "**Key Concepts and Components:**\n",
      "\n",
      "1.  **Data:** This is the raw material.  It could be anything: text, images, audio, video, sensor readings, financial data, etc.  The more relevant and high-quality data you have, the better the AI will typically perform.\n",
      "\n",
      "2.  **Algorithms:**  These are the sets of instructions that the AI uses to learn from the data.  Think of them as the \"recipes\" that tell the computer *how* to analyze the data. There are many different types of algorithms, each suited for different tasks.  Here are a few key types:\n",
      "\n",
      "    *   **Machine Learning (ML):** This is the most common type of AI.  ML algorithms learn patterns from data *without* being explicitly programmed for each specific case.\n",
      "        *   **Supervised Learning:**  The algorithm is trained on labeled data, meaning the data has the correct answers already associated with it.  For example, a dataset of images of cats and dogs where each image is labeled as \"cat\" or \"dog.\" The algorithm learns to map the input (image) to the output (label).  Think of it like learning from a teacher who gives you the correct answers to practice problems.  Common examples include classification (is this spam or not spam?) and regression (what will the price of this house be?).\n",
      "        *   **Unsupervised Learning:** The algorithm is trained on unlabeled data.  It tries to find patterns, structures, and relationships in the data on its own.  Think of it like exploring a new city without a map - you're trying to figure out the layout and points of interest. Examples include clustering (grouping customers based on purchasing behavior) and dimensionality reduction (simplifying complex data while preserving important information).\n",
      "        *   **Reinforcement Learning (RL):**  The algorithm learns through trial and error.  It receives rewards for correct actions and penalties for incorrect actions.  Think of it like training a dog by giving treats for good behavior. This is often used in robotics, game playing (like AlphaGo), and autonomous driving.\n",
      "\n",
      "    *   **Deep Learning (DL):**  This is a subfield of machine learning that uses artificial neural networks with many layers (hence \"deep\").  These networks are inspired by the structure of the human brain.  Deep learning excels at complex tasks like image recognition, natural language processing, and speech recognition.\n",
      "        *  **Neural Networks:**  Imagine a network of interconnected nodes (like neurons) organized in layers.  Each connection between nodes has a \"weight\" that represents the strength of that connection.  The network learns by adjusting these weights based on the input data and the desired output.  Deep learning uses neural networks with many layers, allowing it to learn more complex patterns.\n",
      "\n",
      "    *   **Rule-Based Systems:** These systems use a set of pre-defined rules to make decisions. They are useful for tasks where the rules are well-defined and don't change frequently.  Think of it like a flowchart - if X is true, then do Y.\n",
      "\n",
      "3.  **Model:**  After the algorithm has been trained on the data, it creates a \"model.\"  The model is essentially a mathematical representation of the patterns it has learned.  This model can then be used to make predictions or decisions on new, unseen data. Think of the model as the learned skill or understanding the AI has developed.\n",
      "\n",
      "4.  **Inference:** This is the process of using the trained model to make predictions or decisions on new data.  This is where the AI actually \"performs\" its task.\n",
      "\n",
      "**The Basic Process in a Nutshell:**\n",
      "\n",
      "1.  **Gather Data:** Collect a large dataset relevant to the task.\n",
      "2.  **Choose an Algorithm:** Select an appropriate algorithm for the task (e.g., supervised learning for classification, reinforcement learning for game playing).\n",
      "3.  **Train the Model:** Feed the data into the algorithm, allowing it to learn patterns and build a model.\n",
      "4.  **Evaluate the Model:** Test the model on a separate dataset to see how well it performs.  Adjust the algorithm or data as needed.\n",
      "5.  **Deploy the Model:** Integrate the model into an application or system to make predictions or decisions on new data.\n",
      "6.  **Monitor and Retrain:**  Continuously monitor the model's performance and retrain it with new data to keep it accurate and up-to-date.\n",
      "\n",
      "**Example: Image Recognition (Identifying Cats in Photos)**\n",
      "\n",
      "1.  **Data:** A large dataset of images labeled \"cat\" and \"not cat.\"\n",
      "2.  **Algorithm:** A deep learning algorithm using a convolutional neural network (CNN). CNNs are particularly good at image recognition.\n",
      "3.  **Training:** The CNN is fed the images and learns to identify features that are characteristic of cats (e.g., pointy ears, whiskers, certain patterns of fur).  The network adjusts its internal weights to accurately classify the images.\n",
      "4.  **Model:** The trained CNN becomes the \"cat detector\" model.\n",
      "5.  **Inference:** A new, unseen image is fed into the model. The model analyzes the image and outputs a probability of whether it contains a cat.\n",
      "\n",
      "**Different Types of AI:**\n",
      "\n",
      "*   **Narrow or Weak AI:** Designed for a specific task (e.g., image recognition, spam filtering).  This is the type of AI we see most commonly today.\n",
      "*   **General or Strong AI (AGI):** Possesses human-level intelligence and can perform any intellectual task that a human being can. This is still largely theoretical.\n",
      "*   **Super AI:** Surpasses human intelligence in all aspects.  This is even more theoretical than AGI and is often explored in science fiction.\n",
      "\n",
      "**Challenges and Considerations:**\n",
      "\n",
      "*   **Bias:** AI models can inherit biases from the data they are trained on. This can lead to unfair or discriminatory outcomes.  It's crucial to address bias in the data and algorithms.\n",
      "*   **Explainability:**  Some AI models, especially deep learning models, are \"black boxes.\" It can be difficult to understand *why* they make certain decisions. This lack of transparency can be a concern in critical applications.\n",
      "*   **Data Requirements:** Many AI algorithms require massive amounts of data to perform well.\n",
      "*   **Ethical Implications:** AI raises many ethical questions about privacy, job displacement, and the potential for misuse.\n",
      "\n",
      "**In Summary:**\n",
      "\n",
      "AI is a powerful technology that allows computers to learn from data and perform tasks that typically require human intelligence. It relies on algorithms, data, and models to make predictions and decisions.  While AI has the potential to solve many problems and improve our lives, it's important to be aware of its limitations and ethical implications.  The field is constantly evolving, so it's important to stay informed about the latest developments.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "client = genai.Client(api_key=os.environ[\"GOOGLE_API_KEY\"])\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash\", contents=\"Explain how AI works\"\n",
    ")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_llm_response(response_text):\n",
    "    \"\"\"\n",
    "    Processes an LLM response, extracts the question-answer pair, \n",
    "    saves each answer as a separate JSON file, and logs all Q&A pairs in qa_log.json.\n",
    "    \"\"\"\n",
    "    # Clean up the response text\n",
    "    data = response_text.replace(\"```json\", \"\").replace(\"```\", \"\").strip()\n",
    "\n",
    "    # Convert string to JSON object\n",
    "    try:\n",
    "        json_data = json.loads(data)\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"Error: Invalid JSON format.\")\n",
    "        return\n",
    "\n",
    "    # Ensure the LLM_answers directory exists\n",
    "    llm_answers_dir = \"LLM_answers\"\n",
    "    os.makedirs(llm_answers_dir, exist_ok=True)\n",
    "\n",
    "    # Generate a unique filename with timestamp\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    json_filename = f\"{llm_answers_dir}/answer_{timestamp}.json\"\n",
    "\n",
    "    # Save individual answer JSON\n",
    "    with open(json_filename, \"w\", encoding=\"utf-8\") as json_file:\n",
    "        json.dump(json_data, json_file, indent=4)\n",
    "\n",
    "    # Log all Q&A pairs in a central file\n",
    "    log_filename = \"qa_log.json\"\n",
    "\n",
    "    # Load existing log file or create a new list\n",
    "    if os.path.exists(log_filename):\n",
    "        with open(log_filename, \"r\", encoding=\"utf-8\") as log_file:\n",
    "            try:\n",
    "                qa_log = json.load(log_file)\n",
    "            except json.JSONDecodeError:\n",
    "                qa_log = []\n",
    "    else:\n",
    "        qa_log = []\n",
    "\n",
    "    # Append new question-answer pair to the log\n",
    "    qa_log.append(json_data)\n",
    "\n",
    "    # Save updated log file\n",
    "    with open(log_filename, \"w\", encoding=\"utf-8\") as log_file:\n",
    "        json.dump(qa_log, log_file, indent=4)\n",
    "\n",
    "    print(f\"Saved answer as {json_filename} and updated {log_filename}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "folder_path = r\"divider\\ddls\"\n",
    "list_of_text = []\n",
    "sql_files = sorted([f for f in os.listdir(folder_path) if f.endswith(\".sql\")])\n",
    "#comment_files = sorted([f for f in os.listdir(folder_path) if f.endswith(\".comment\")])\n",
    "\n",
    "for filename in sql_files:\n",
    "    sql_file_path = os.path.join(folder_path, filename)\n",
    "\n",
    "    print(\"sql path::::\", sql_file_path)\n",
    "    with open(sql_file_path, \"r\") as file:\n",
    "        sql_content = file.read()\n",
    "        \n",
    "        print(f\"SQL script {filename} executed successfully.\")\n",
    "\n",
    "    comment_file_path = sql_file_path.replace(\".sql\", \".comment\")\n",
    "    print(comment_file_path)\n",
    "    try:\n",
    "        with open(comment_file_path, \"r\") as file:\n",
    "            comment_content = file.read()\n",
    "\n",
    "            print(f\"Comment script {filename} executed successfully.\")\n",
    "            \n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found at {comment_file_path}\")\n",
    "\n",
    "    list_of_text.append((sql_content, comment_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define schema\n",
    "allowed_nodes = [\"ColumnName\", \n",
    "                 \"TableName\",\n",
    "                 \"Data Type\",\n",
    "                 \"SchemaName\",\n",
    "                 \"Comment\",\n",
    "                 \"Summary\"\n",
    "                 ]\n",
    "\n",
    "allowed_relationships = [\n",
    "(\"ColumnName\", \"PART_OF\", \"TableName\"), \n",
    "(\"ColumnName\", \"TYPE_OF\", \"Data Type\"), \n",
    "(\"TableName\", \"PART_OF\", \"SchemaName\"), \n",
    "(\"Comment\", \"DESCRIBES\", \"ColumnName\"), \n",
    "(\"Summary\", \"DESCRIBES\", \"TableName\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = genai.Client(api_key=os.environ[\"GOOGLE_API_KEY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved answer as LLM_answers/answer_20250305_022711.json and updated qa_log.json.\n",
      "Saved answer as LLM_answers/answer_20250305_022715.json and updated qa_log.json.\n",
      "Saved answer as LLM_answers/answer_20250305_022724.json and updated qa_log.json.\n",
      "Saved answer as LLM_answers/answer_20250305_022736.json and updated qa_log.json.\n",
      "Saved answer as LLM_answers/answer_20250305_022750.json and updated qa_log.json.\n",
      "Saved answer as LLM_answers/answer_20250305_022811.json and updated qa_log.json.\n",
      "Saved answer as LLM_answers/answer_20250305_022828.json and updated qa_log.json.\n",
      "Saved answer as LLM_answers/answer_20250305_022837.json and updated qa_log.json.\n",
      "Saved answer as LLM_answers/answer_20250305_022849.json and updated qa_log.json.\n",
      "Saved answer as LLM_answers/answer_20250305_022901.json and updated qa_log.json.\n",
      "Saved answer as LLM_answers/answer_20250305_022906.json and updated qa_log.json.\n",
      "Saved answer as LLM_answers/answer_20250305_022916.json and updated qa_log.json.\n",
      "Saved answer as LLM_answers/answer_20250305_022929.json and updated qa_log.json.\n",
      "Saved answer as LLM_answers/answer_20250305_022936.json and updated qa_log.json.\n",
      "Saved answer as LLM_answers/answer_20250305_022947.json and updated qa_log.json.\n",
      "Saved answer as LLM_answers/answer_20250305_023004.json and updated qa_log.json.\n",
      "Saved answer as LLM_answers/answer_20250305_023007.json and updated qa_log.json.\n",
      "Saved answer as LLM_answers/answer_20250305_023011.json and updated qa_log.json.\n",
      "Saved answer as LLM_answers/answer_20250305_023015.json and updated qa_log.json.\n",
      "Saved answer as LLM_answers/answer_20250305_023019.json and updated qa_log.json.\n",
      "Saved answer as LLM_answers/answer_20250305_023024.json and updated qa_log.json.\n",
      "Saved answer as LLM_answers/answer_20250305_023040.json and updated qa_log.json.\n"
     ]
    }
   ],
   "source": [
    "sys_instruct=f\"\"\"You are a system and you need to extract entities and knowledge from DDL scripts\n",
    "\n",
    "### Allowed Nodes ###\n",
    "\n",
    "{allowed_nodes}\n",
    "\n",
    "### Allowed Relationships ###\n",
    "\n",
    "{allowed_relationships}\n",
    "\n",
    "### For \"Summary\" infere what kind of information would be stored there ###\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "for pair in list_of_text:\n",
    "    text = [pair[0], pair[1]]\n",
    "\n",
    "    response = client.models.generate_content(\n",
    "        model=\"gemini-2.0-flash\",\n",
    "        config=types.GenerateContentConfig(\n",
    "        # max_output_tokens=500,\n",
    "            temperature=0.1,\n",
    "            system_instruction=sys_instruct),\n",
    "        contents=text\n",
    "    )\n",
    "\n",
    "    process_llm_response(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(response.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
