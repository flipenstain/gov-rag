{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "import pandas as pd\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQL query successfully written to 'C:\\lopu-kg-test\\project\\src\\main\\sql_for_pipelines\\1_my_script.sql'.\n",
      "SQL query successfully written to 'C:\\lopu-kg-test\\project\\src\\main\\sql_for_pipelines\\2_my_script.sql'.\n",
      "SQL query successfully written to 'C:\\lopu-kg-test\\project\\src\\main\\sql_for_pipelines\\3_my_script.sql'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def save_sql_to_file(sql_string: str, script_name: str):\n",
    "    \"\"\"\n",
    "    Creates a storage folder (if it doesn't exist) and writes the given SQL string\n",
    "    to a .sql file within that folder. If a file with the same base name exists,\n",
    "    it prepends an increasing number (1, 2, 3, ...) to the filename.\n",
    "\n",
    "    Args:\n",
    "        sql_string: The SQL query string to be saved.\n",
    "        script_name: The base name of the script (used for the filename).\n",
    "    \"\"\"\n",
    "    folder_name = \"C:\\\\lopu-kg-test\\\\project\\\\src\\\\main\\\\sql_for_pipelines\"\n",
    "\n",
    "    # Create the storage folder if it doesn't exist\n",
    "    if not os.path.exists(folder_name):\n",
    "        try:\n",
    "            os.makedirs(folder_name)\n",
    "            print(f\"Folder '{folder_name}' created successfully.\")\n",
    "        except OSError as e:\n",
    "            print(f\"Error creating folder '{folder_name}': {e}\")\n",
    "            return\n",
    "\n",
    "    base_filename = f\"{script_name}.sql\"\n",
    "    counter = 1\n",
    "    file_path = os.path.join(folder_name, f\"{counter}_{base_filename}\")\n",
    "\n",
    "    while os.path.exists(file_path):\n",
    "        counter += 1\n",
    "        file_path = os.path.join(folder_name, f\"{counter}_{base_filename}\")\n",
    "\n",
    "    # Write the SQL string to the file\n",
    "    try:\n",
    "        with open(file_path, \"w\") as f:\n",
    "            f.write(sql_string)\n",
    "        print(f\"SQL query successfully written to '{file_path}'.\")\n",
    "    except IOError as e:\n",
    "        print(f\"Error writing to file '{file_path}': {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "\n",
    "def get_duckdb_query_stats(conn: duckdb.DuckDBPyConnection, query: str) -> dict:\n",
    "    \"\"\"Executes a DuckDB query and returns its statistics.\"\"\"\n",
    "    try:\n",
    "        conn.execute(query)\n",
    "        #Get the latest query execution info.\n",
    "        result = conn.execute(\"SELECT rows, execution_time FROM duckdb_queries ORDER BY finished DESC LIMIT 1\").fetchone()\n",
    "        if result:\n",
    "            rows, execution_time = result\n",
    "            return {\"rows\": rows, \"execution_time\": execution_time}\n",
    "        else:\n",
    "            return {\"error\": \"Could not retrieve query statistics.\"}\n",
    "\n",
    "    except duckdb.Error as e:\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "def get_duckdb_copy_stats(conn: duckdb.DuckDBPyConnection, copy_command: str) -> dict:\n",
    "    \"\"\"Executes a DuckDB COPY command and returns its statistics.\"\"\"\n",
    "    try:\n",
    "        conn.execute(copy_command)\n",
    "        #Get the latest copy command execution info.\n",
    "        result = conn.execute(\"SELECT rows, bytes_written, execution_time FROM duckdb_queries ORDER BY finished DESC LIMIT 1\").fetchone()\n",
    "        if result:\n",
    "            rows, bytes_written, execution_time = result\n",
    "            return {\"rows\": rows, \"bytes_written\": bytes_written, \"execution_time\": execution_time}\n",
    "        else:\n",
    "            return {\"error\": \"Could not retrieve copy statistics.\"}\n",
    "\n",
    "    except duckdb.Error as e:\n",
    "        return {\"error\": str(e)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def xml_to_dataframe(xml_file_path):\n",
    "    \"\"\"\n",
    "    Parses an XML file and converts it into a pandas DataFrame.\n",
    "\n",
    "    Args:\n",
    "        xml_file_path (str): The path to the XML file.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: The DataFrame containing the XML data, or None if an error occurs.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        tree = ET.parse(xml_file_path)\n",
    "        root = tree.getroot()\n",
    "\n",
    "        data = []\n",
    "        for action in root:\n",
    "            action_data = {}\n",
    "            # Extract Action attributes\n",
    "            for key, value in action.attrib.items():\n",
    "                action_data[\"Action.\" + key.split(\"}\")[-1]] = value\n",
    "\n",
    "            for element in action:\n",
    "                for key, column0 in element.attrib.items():\n",
    "                    action_data[\"Customer.\" + key.split(\"}\")[-1]] = column0 # value, oli siin enne 04.04 muudatus\n",
    "                if len(element) == 0:  # Simple element\n",
    "                    action_data[element.tag.split(\"}\")[-1]] = element.text\n",
    "                else:  # Nested element\n",
    "                    for sub_element in element:\n",
    "                        for key, value in sub_element.attrib.items():\n",
    "                            action_data[\"Account.\" + key.split(\"}\")[-1]] = value\n",
    "                        if len(sub_element) == 0:\n",
    "                            action_data[element.tag.split(\"}\")[-1] + \".\" + sub_element.tag.split(\"}\")[-1]] = sub_element.text\n",
    "                        else:\n",
    "                            for sub_sub_element in sub_element:\n",
    "                                if len(sub_sub_element) == 0:\n",
    "                                    action_data[element.tag.split(\"}\")[-1] + \".\" + sub_element.tag.split(\"}\")[-1] + \".\" + sub_sub_element.tag.split(\"}\")[-1]] = sub_sub_element.text\n",
    "                                else:\n",
    "                                    for sub_sub_sub_element in sub_sub_element:\n",
    "                                        action_data[element.tag.split(\"}\")[-1] + \".\" + sub_element.tag.split(\"}\")[-1] + \".\" + sub_sub_element.tag.split(\"}\")[-1] + \".\" + sub_sub_sub_element.tag.split(\"}\")[-1]] = sub_sub_sub_element.text\n",
    "            data.append(action_data)\n",
    "\n",
    "        df = pd.DataFrame(data)\n",
    "        return df\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing XML file: {e}\")\n",
    "        return None\n",
    "\n",
    "path_to_xml = \"C:\\lopu-kg-test\\project\\src\\data\\Batch1\\CustomerMgmt.xml\"\n",
    "\n",
    "xml_dataframe = xml_to_dataframe(path_to_xml)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_columns(df):\n",
    "    \"\"\"\n",
    "    Renames DataFrame columns by extracting the last part after '.', \n",
    "    and appends a counter if duplicates are found.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The DataFrame to rename columns.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The DataFrame with renamed columns.\n",
    "    \"\"\"\n",
    "    new_columns = []\n",
    "    seen_columns = {}  # Track seen column names and their counts\n",
    "\n",
    "    for col in df.columns:\n",
    "        parts = col.split('.')\n",
    "        new_col = parts[-1]  # Extract the last part\n",
    "\n",
    "        if new_col in seen_columns:\n",
    "            seen_columns[new_col] += 1\n",
    "            new_col = f\"{new_col}_{seen_columns[new_col]}\"  # Append a counter\n",
    "        else:\n",
    "            seen_columns[new_col] = 0\n",
    "\n",
    "        new_columns.append(new_col)\n",
    "\n",
    "    df.columns = new_columns\n",
    "    return df\n",
    "\n",
    "\n",
    "xml_dataframe = rename_columns(xml_dataframe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQL query successfully written to 'C:\\lopu-kg-test\\project\\src\\main\\sql_for_pipelines\\1_wh_db.DimDate.sql'.\n",
      "Loaded Date.txt into wh_db.DimDate\n",
      "src/data/Batch1\\Date.txt\n",
      "SQL query successfully written to 'C:\\lopu-kg-test\\project\\src\\main\\sql_for_pipelines\\1_wh_db.DimTime.sql'.\n",
      "Loaded Time.txt into wh_db.DimTime\n",
      "src/data/Batch1\\Time.txt\n",
      "SQL query successfully written to 'C:\\lopu-kg-test\\project\\src\\main\\sql_for_pipelines\\1_wh_db.StatusType.sql'.\n",
      "Loaded StatusType.txt into wh_db.StatusType\n",
      "src/data/Batch1\\StatusType.txt\n",
      "SQL query successfully written to 'C:\\lopu-kg-test\\project\\src\\main\\sql_for_pipelines\\1_wh_db.TaxRate.sql'.\n",
      "Loaded TaxRate.txt into wh_db.TaxRate\n",
      "src/data/Batch1\\TaxRate.txt\n",
      "SQL query successfully written to 'C:\\lopu-kg-test\\project\\src\\main\\sql_for_pipelines\\1_wh_db.TradeType.sql'.\n",
      "Loaded TradeType.txt into wh_db.TradeType\n",
      "src/data/Batch1\\TradeType.txt\n",
      "SQL query successfully written to 'C:\\lopu-kg-test\\project\\src\\main\\sql_for_pipelines\\1_temp_broker.sql'.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "sql(): incompatible function arguments. The following argument types are supported:\n    1. (self: duckdb.duckdb.DuckDBPyConnection, query: object, *, alias: str = '', params: object = None) -> duckdb.duckdb.DuckDBPyRelation\n\nInvoked with: <duckdb.duckdb.DuckDBPyConnection object at 0x0000022C2E0F7830>, \"\\n                INSERT INTO wh_db.DimBroker\\n                SELECT \\n                    employeeid sk_brokerid,\\n                    employeeid brokerid,\\n                    managerid,\\n                    employeefirstname firstname,\\n                    employeelastname lastname,\\n                    employeemi middleinitial,\\n                    employeebranch branch,\\n                    employeeoffice office,\\n                    employeephone phone,\\n                    true iscurrent,\\n                    1 batchid, --temp, later read from db\\n                    (SELECT min(datevalue::DATE) as effectivedate FROM wh_db.DimDate) effectivedate,\\n                    '9999-12-31'::DATE enddate\\n                    FROM temp_broker;\\n                \", 'wh_db.DimBroker'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 69\u001b[0m\n\u001b[0;32m     67\u001b[0m db_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minitial_db.duckdb\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     68\u001b[0m src_folder \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msrc/data/Batch1\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 69\u001b[0m con \u001b[38;5;241m=\u001b[39m \u001b[43mload_data_to_duckdb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdb_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_folder\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;66;03m# Test loading\u001b[39;00m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;66;03m#print(con.sql(\"SELECT * FROM wh_db.DimTime limit 10\").fetchdf(10))\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[17], line 59\u001b[0m, in \u001b[0;36mload_data_to_duckdb\u001b[1;34m(db_path, src_folder)\u001b[0m\n\u001b[0;32m     57\u001b[0m save_sql_to_file(query, table_name)\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHR.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 59\u001b[0m     \u001b[43mcon\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msql\u001b[49m\u001b[43m(\u001b[49m\u001b[43minsert_target_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwh_db.DimBroker\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     60\u001b[0m     save_sql_to_file(insert_target_query, table_name)\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoaded \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m into \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtable_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: sql(): incompatible function arguments. The following argument types are supported:\n    1. (self: duckdb.duckdb.DuckDBPyConnection, query: object, *, alias: str = '', params: object = None) -> duckdb.duckdb.DuckDBPyRelation\n\nInvoked with: <duckdb.duckdb.DuckDBPyConnection object at 0x0000022C2E0F7830>, \"\\n                INSERT INTO wh_db.DimBroker\\n                SELECT \\n                    employeeid sk_brokerid,\\n                    employeeid brokerid,\\n                    managerid,\\n                    employeefirstname firstname,\\n                    employeelastname lastname,\\n                    employeemi middleinitial,\\n                    employeebranch branch,\\n                    employeeoffice office,\\n                    employeephone phone,\\n                    true iscurrent,\\n                    1 batchid, --temp, later read from db\\n                    (SELECT min(datevalue::DATE) as effectivedate FROM wh_db.DimDate) effectivedate,\\n                    '9999-12-31'::DATE enddate\\n                    FROM temp_broker;\\n                \", 'wh_db.DimBroker'"
     ]
    }
   ],
   "source": [
    "def load_data_to_duckdb(db_path, src_folder):\n",
    "    data_dict = {\n",
    "        \"Date.txt\": \"wh_db.DimDate\",\n",
    "        \"Time.txt\": \"wh_db.DimTime\",\n",
    "        \"StatusType.txt\": \"wh_db.StatusType\",\n",
    "        \"TaxRate.txt\": \"wh_db.TaxRate\",\n",
    "        \"TradeType.txt\": \"wh_db.TradeType\",\n",
    "        \"HR.csv\": \"temp_broker\", #wh_db moved out to take into account SK_ID\n",
    "        \"Industry.txt\": \"wh_db.industry\"\n",
    "        # \"FinwireCMP.txt\": \"wh_db.DimCompany\"\n",
    "    }\n",
    "    \n",
    "    con = duckdb.connect(database=db_path)\n",
    "    \n",
    "    for file_name, table_name in data_dict.items():\n",
    "        file_path = os.path.join(src_folder, file_name)\n",
    "        \n",
    "        if file_name == \"HR.csv\":\n",
    "            query = f\"\"\"\n",
    "                CREATE OR REPLACE TEMP TABLE {table_name} AS \n",
    "                SELECT * FROM read_csv('{file_path}', delim=',', columns={{\n",
    "                    'employeeid': 'BIGINT',\n",
    "                    'managerid': 'BIGINT',\n",
    "                    'employeefirstname': 'STRING',\n",
    "                    'employeelastname': 'STRING',\n",
    "                    'employeemi': 'STRING',\n",
    "                    'employeejobcode': 'STRING',\n",
    "                    'employeebranch': 'STRING',\n",
    "                    'employeeoffice': 'STRING',\n",
    "                    'employeephone': 'STRING'\n",
    "                }}, header=False) \n",
    "                WHERE employeejobcode = '314';\n",
    "            \"\"\"\n",
    "\n",
    "            insert_target_query = f\"\"\"\n",
    "                INSERT INTO wh_db.DimBroker\n",
    "                SELECT \n",
    "                    employeeid sk_brokerid,\n",
    "                    employeeid brokerid,\n",
    "                    managerid,\n",
    "                    employeefirstname firstname,\n",
    "                    employeelastname lastname,\n",
    "                    employeemi middleinitial,\n",
    "                    employeebranch branch,\n",
    "                    employeeoffice office,\n",
    "                    employeephone phone,\n",
    "                    true iscurrent,\n",
    "                    1 batchid, --temp, later read from db\n",
    "                    (SELECT min(datevalue::DATE) as effectivedate FROM wh_db.DimDate) effectivedate,\n",
    "                    '9999-12-31'::DATE enddate\n",
    "                    FROM temp_broker;\n",
    "                \"\"\"\n",
    "        else:\n",
    "            query = f\"COPY {table_name} FROM '{file_path}' (DELIMITER '|');\"\n",
    "\n",
    "        con.sql(query)\n",
    "        save_sql_to_file(query, table_name)\n",
    "        if file_name == \"HR.csv\":\n",
    "            con.sql(insert_target_query)\n",
    "            save_sql_to_file(insert_target_query, \"wh_db.DimBroker\")\n",
    "        print(f\"Loaded {file_name} into {table_name}\")\n",
    "        print(file_path)\n",
    "    \n",
    "    return con\n",
    "\n",
    "# Example usage:\n",
    "db_path = 'initial_db.duckdb'\n",
    "src_folder = 'src/data/Batch1'\n",
    "con = load_data_to_duckdb(db_path, src_folder)\n",
    "\n",
    "# Test loading\n",
    "#print(con.sql(\"SELECT * FROM wh_db.DimTime limit 10\").fetchdf(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQL query successfully written to 'C:\\lopu-kg-test\\project\\src\\main\\sql_for_pipelines\\1_wh_db.DimBroker.sql'.\n"
     ]
    }
   ],
   "source": [
    "insert_target_query = f\"\"\"\n",
    "                INSERT INTO wh_db.DimBroker\n",
    "                SELECT \n",
    "                    employeeid sk_brokerid,\n",
    "                    employeeid brokerid,\n",
    "                    managerid,\n",
    "                    employeefirstname firstname,\n",
    "                    employeelastname lastname,\n",
    "                    employeemi middleinitial,\n",
    "                    employeebranch branch,\n",
    "                    employeeoffice office,\n",
    "                    employeephone phone,\n",
    "                    true iscurrent,\n",
    "                    1 batchid, --temp, later read from db\n",
    "                    (SELECT min(datevalue::DATE) as effectivedate FROM wh_db.DimDate) effectivedate,\n",
    "                    '9999-12-31'::DATE enddate\n",
    "                    FROM temp_broker;\n",
    "                \"\"\"\n",
    "\n",
    "con_path = r\"initial_db.duckdb\"\n",
    "con = duckdb.connect(con_path)\n",
    "save_sql_to_file(insert_target_query, \"wh_db.DimBroker\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             COLUMN_COMMENT\n",
      "0  Surrogate key for broker\n"
     ]
    }
   ],
   "source": [
    "print(con.execute(\"select COLUMN_COMMENT from information_schema.columns where table_name = 'DimBroker' limit 1\").fetchdf())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('sk_brokerid', 'BIGINT', 'Surrogate key for broker'), ('brokerid', 'BIGINT', 'Natural key for broker'), ('managerid', 'BIGINT', 'Natural key for managerâ€™s HR record'), ('firstname', 'VARCHAR', 'First name'), ('lastname', 'VARCHAR', 'Last Name'), ('middleinitial', 'VARCHAR', 'Middle initial'), ('branch', 'VARCHAR', 'Facility in which employee has office'), ('office', 'VARCHAR', 'Office number or description'), ('phone', 'VARCHAR', 'Employee phone number'), ('iscurrent', 'BOOLEAN', 'True if this is the current record'), ('batchid', 'INTEGER', 'Batch ID when this record was inserted'), ('effectivedate', 'DATE', 'Beginning of date range when this record was the current record'), ('enddate', 'DATE', 'Ending of date range when this record was the current record. A record that is not expired will use the date 9999-12-31.')]\n"
     ]
    }
   ],
   "source": [
    "def get_table_schema(db_path, table_name):\n",
    "    query = f\"\"\"\n",
    "        SELECT \n",
    "            column_name AS name, \n",
    "            data_type AS type, \n",
    "            COLUMN_COMMENT AS description\n",
    "        FROM information_schema.columns\n",
    "        WHERE table_name = '{table_name}'\n",
    "    \"\"\"\n",
    "\n",
    "    con = duckdb.connect(database=db_path)\n",
    "    result = con.sql(query).fetchall()\n",
    "\n",
    "    # Format result into the required structure\n",
    "    schema_columns = [\n",
    "        {\"name\": row[0], \"type\": row[1], \"description\": row[2] if row[2] else \"\"}\n",
    "        for row in result\n",
    "    ]\n",
    "\n",
    "    return result\n",
    "\n",
    "# Example usage\n",
    "db_path = 'initial_db.duckdb'\n",
    "table_name = 'DimBroker'\n",
    "schema_columns = get_table_schema(db_path, table_name)\n",
    "\n",
    "print(schema_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQL query successfully written to 'C:\\lopu-kg-test\\project\\src\\main\\sql_for_pipelines\\1_wh_db_stage.CustomerMgmt.sql'.\n"
     ]
    }
   ],
   "source": [
    "stage_CustomerMgmt = \"\"\" \n",
    "        CREATE OR REPLACE TABLE wh_db_stage.CustomerMgmt  AS  \n",
    "        SELECT\n",
    "        try_cast(C_ID as BIGINT) customerid,\n",
    "        try_cast(CA_ID as BIGINT) accountid,\n",
    "        try_cast(CA_B_ID as BIGINT) brokerid,\n",
    "        nullif(C_TAX_ID, '') taxid,\n",
    "        nullif(CA_NAME, '') accountdesc,\n",
    "        try_cast(CA_TAX_ST as TINYINT) taxstatus,\n",
    "        CASE\n",
    "            WHEN ActionType IN ('NEW', 'ADDACCT', 'UPDACCT', 'UPDCUST') THEN 'Active'\n",
    "            WHEN ActionType IN ('CLOSEACCT', 'INACT') THEN 'Inactive'\n",
    "            ELSE NULL\n",
    "        END AS status,\n",
    "        nullif(C_L_NAME, '') lastname,\n",
    "        nullif(C_F_NAME, '') firstname,\n",
    "        nullif(C_M_NAME, '') middleinitial,\n",
    "        nullif(upper(C_GNDR), '') gender,\n",
    "        try_cast(C_TIER as TINYINT) tier,\n",
    "        try_cast(C_DOB as DATE) dob,\n",
    "        nullif(C_ADLINE1, '') addressline1,\n",
    "        nullif(C_ADLINE2, '') addressline2,\n",
    "        nullif(C_ZIPCODE, '') postalcode,\n",
    "        nullif(C_CITY, '') city,\n",
    "        nullif(C_STATE_PROV, '') stateprov,\n",
    "        nullif(C_CTRY, '') country,\n",
    "        CASE\n",
    "            WHEN nullif(C_LOCAL, '') IS NOT NULL THEN\n",
    "                concat(\n",
    "                    CASE WHEN nullif(C_CTRY_CODE, '') IS NOT NULL THEN '+' || C_CTRY_CODE || ' ' ELSE '' END,\n",
    "                    CASE WHEN nullif(C_AREA_CODE, '') IS NOT NULL THEN '(' || C_AREA_CODE || ') ' ELSE '' END,\n",
    "                    C_LOCAL,\n",
    "                    COALESCE(C_EXT, '')\n",
    "                )\n",
    "            ELSE NULL\n",
    "        END AS phone1,\n",
    "        CASE\n",
    "            WHEN nullif(C_LOCAL_1, '') IS NOT NULL THEN\n",
    "                concat(\n",
    "                    CASE WHEN nullif(C_CTRY_CODE_1, '') IS NOT NULL THEN '+' || C_CTRY_CODE_1 || ' ' ELSE '' END,\n",
    "                    CASE WHEN nullif(C_AREA_CODE_1, '') IS NOT NULL THEN '(' || C_AREA_CODE_1 || ') ' ELSE '' END,\n",
    "                    C_LOCAL_1,\n",
    "                    COALESCE(C_EXT_1, '')\n",
    "                )\n",
    "            ELSE NULL\n",
    "        END AS phone2,\n",
    "        CASE\n",
    "            WHEN nullif(C_LOCAL_2, '') IS NOT NULL THEN\n",
    "                concat(\n",
    "                    CASE WHEN nullif(C_CTRY_CODE_2, '') IS NOT NULL THEN '+' || C_CTRY_CODE_2 || ' ' ELSE '' END,\n",
    "                    CASE WHEN nullif(C_AREA_CODE_2, '') IS NOT NULL THEN '(' || C_AREA_CODE_2 || ') ' ELSE '' END,\n",
    "                    C_LOCAL_2,\n",
    "                    COALESCE(C_EXT_2, '')\n",
    "                )\n",
    "            ELSE NULL\n",
    "        END AS phone3,\n",
    "        nullif(C_PRIM_EMAIL, '') email1,\n",
    "        nullif(C_ALT_EMAIL, '') email2,\n",
    "        nullif(C_LCL_TX_ID, '') lcl_tx_id,\n",
    "        nullif(C_NAT_TX_ID, '') nat_tx_id,\n",
    "        try_cast(ActionTS as TIMESTAMP) update_ts,\n",
    "        ActionType\n",
    "           \n",
    "            FROM xml_dataframe\"\"\"\n",
    "\n",
    "con.sql(stage_CustomerMgmt)\n",
    "save_sql_to_file(insert_target_query, \"wh_db_stage.CustomerMgmt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_sql_to_file(insert_target_query, \"wh_db.DimBroker\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['src/data/Batch1\\\\FINWIRE1967Q1',\n",
       " 'src/data/Batch1\\\\FINWIRE1967Q2',\n",
       " 'src/data/Batch1\\\\FINWIRE1967Q3',\n",
       " 'src/data/Batch1\\\\FINWIRE1967Q4',\n",
       " 'src/data/Batch1\\\\FINWIRE1968Q1',\n",
       " 'src/data/Batch1\\\\FINWIRE1968Q2',\n",
       " 'src/data/Batch1\\\\FINWIRE1968Q3',\n",
       " 'src/data/Batch1\\\\FINWIRE1968Q4',\n",
       " 'src/data/Batch1\\\\FINWIRE1969Q1',\n",
       " 'src/data/Batch1\\\\FINWIRE1969Q2',\n",
       " 'src/data/Batch1\\\\FINWIRE1969Q3',\n",
       " 'src/data/Batch1\\\\FINWIRE1969Q4',\n",
       " 'src/data/Batch1\\\\FINWIRE1970Q1',\n",
       " 'src/data/Batch1\\\\FINWIRE1970Q2',\n",
       " 'src/data/Batch1\\\\FINWIRE1970Q3',\n",
       " 'src/data/Batch1\\\\FINWIRE1970Q4',\n",
       " 'src/data/Batch1\\\\FINWIRE1971Q1',\n",
       " 'src/data/Batch1\\\\FINWIRE1971Q2',\n",
       " 'src/data/Batch1\\\\FINWIRE1971Q3',\n",
       " 'src/data/Batch1\\\\FINWIRE1971Q4',\n",
       " 'src/data/Batch1\\\\FINWIRE1972Q1',\n",
       " 'src/data/Batch1\\\\FINWIRE1972Q2',\n",
       " 'src/data/Batch1\\\\FINWIRE1972Q3',\n",
       " 'src/data/Batch1\\\\FINWIRE1972Q4',\n",
       " 'src/data/Batch1\\\\FINWIRE1973Q1',\n",
       " 'src/data/Batch1\\\\FINWIRE1973Q2',\n",
       " 'src/data/Batch1\\\\FINWIRE1973Q3',\n",
       " 'src/data/Batch1\\\\FINWIRE1973Q4',\n",
       " 'src/data/Batch1\\\\FINWIRE1974Q1',\n",
       " 'src/data/Batch1\\\\FINWIRE1974Q2',\n",
       " 'src/data/Batch1\\\\FINWIRE1974Q3',\n",
       " 'src/data/Batch1\\\\FINWIRE1974Q4',\n",
       " 'src/data/Batch1\\\\FINWIRE1975Q1',\n",
       " 'src/data/Batch1\\\\FINWIRE1975Q2',\n",
       " 'src/data/Batch1\\\\FINWIRE1975Q3',\n",
       " 'src/data/Batch1\\\\FINWIRE1975Q4',\n",
       " 'src/data/Batch1\\\\FINWIRE1976Q1',\n",
       " 'src/data/Batch1\\\\FINWIRE1976Q2',\n",
       " 'src/data/Batch1\\\\FINWIRE1976Q3',\n",
       " 'src/data/Batch1\\\\FINWIRE1976Q4',\n",
       " 'src/data/Batch1\\\\FINWIRE1977Q1',\n",
       " 'src/data/Batch1\\\\FINWIRE1977Q2',\n",
       " 'src/data/Batch1\\\\FINWIRE1977Q3',\n",
       " 'src/data/Batch1\\\\FINWIRE1977Q4',\n",
       " 'src/data/Batch1\\\\FINWIRE1978Q1',\n",
       " 'src/data/Batch1\\\\FINWIRE1978Q2',\n",
       " 'src/data/Batch1\\\\FINWIRE1978Q3',\n",
       " 'src/data/Batch1\\\\FINWIRE1978Q4',\n",
       " 'src/data/Batch1\\\\FINWIRE1979Q1',\n",
       " 'src/data/Batch1\\\\FINWIRE1979Q2',\n",
       " 'src/data/Batch1\\\\FINWIRE1979Q3',\n",
       " 'src/data/Batch1\\\\FINWIRE1979Q4',\n",
       " 'src/data/Batch1\\\\FINWIRE1980Q1',\n",
       " 'src/data/Batch1\\\\FINWIRE1980Q2',\n",
       " 'src/data/Batch1\\\\FINWIRE1980Q3',\n",
       " 'src/data/Batch1\\\\FINWIRE1980Q4',\n",
       " 'src/data/Batch1\\\\FINWIRE1981Q1',\n",
       " 'src/data/Batch1\\\\FINWIRE1981Q2',\n",
       " 'src/data/Batch1\\\\FINWIRE1981Q3',\n",
       " 'src/data/Batch1\\\\FINWIRE1981Q4',\n",
       " 'src/data/Batch1\\\\FINWIRE1982Q1',\n",
       " 'src/data/Batch1\\\\FINWIRE1982Q2',\n",
       " 'src/data/Batch1\\\\FINWIRE1982Q3',\n",
       " 'src/data/Batch1\\\\FINWIRE1982Q4',\n",
       " 'src/data/Batch1\\\\FINWIRE1983Q1',\n",
       " 'src/data/Batch1\\\\FINWIRE1983Q2',\n",
       " 'src/data/Batch1\\\\FINWIRE1983Q3',\n",
       " 'src/data/Batch1\\\\FINWIRE1983Q4',\n",
       " 'src/data/Batch1\\\\FINWIRE1984Q1',\n",
       " 'src/data/Batch1\\\\FINWIRE1984Q2',\n",
       " 'src/data/Batch1\\\\FINWIRE1984Q3',\n",
       " 'src/data/Batch1\\\\FINWIRE1984Q4',\n",
       " 'src/data/Batch1\\\\FINWIRE1985Q1',\n",
       " 'src/data/Batch1\\\\FINWIRE1985Q2',\n",
       " 'src/data/Batch1\\\\FINWIRE1985Q3',\n",
       " 'src/data/Batch1\\\\FINWIRE1985Q4',\n",
       " 'src/data/Batch1\\\\FINWIRE1986Q1',\n",
       " 'src/data/Batch1\\\\FINWIRE1986Q2',\n",
       " 'src/data/Batch1\\\\FINWIRE1986Q3',\n",
       " 'src/data/Batch1\\\\FINWIRE1986Q4',\n",
       " 'src/data/Batch1\\\\FINWIRE1987Q1',\n",
       " 'src/data/Batch1\\\\FINWIRE1987Q2',\n",
       " 'src/data/Batch1\\\\FINWIRE1987Q3',\n",
       " 'src/data/Batch1\\\\FINWIRE1987Q4',\n",
       " 'src/data/Batch1\\\\FINWIRE1988Q1',\n",
       " 'src/data/Batch1\\\\FINWIRE1988Q2',\n",
       " 'src/data/Batch1\\\\FINWIRE1988Q3',\n",
       " 'src/data/Batch1\\\\FINWIRE1988Q4',\n",
       " 'src/data/Batch1\\\\FINWIRE1989Q1',\n",
       " 'src/data/Batch1\\\\FINWIRE1989Q2',\n",
       " 'src/data/Batch1\\\\FINWIRE1989Q3',\n",
       " 'src/data/Batch1\\\\FINWIRE1989Q4',\n",
       " 'src/data/Batch1\\\\FINWIRE1990Q1',\n",
       " 'src/data/Batch1\\\\FINWIRE1990Q2',\n",
       " 'src/data/Batch1\\\\FINWIRE1990Q3',\n",
       " 'src/data/Batch1\\\\FINWIRE1990Q4',\n",
       " 'src/data/Batch1\\\\FINWIRE1991Q1',\n",
       " 'src/data/Batch1\\\\FINWIRE1991Q2',\n",
       " 'src/data/Batch1\\\\FINWIRE1991Q3',\n",
       " 'src/data/Batch1\\\\FINWIRE1991Q4',\n",
       " 'src/data/Batch1\\\\FINWIRE1992Q1',\n",
       " 'src/data/Batch1\\\\FINWIRE1992Q2',\n",
       " 'src/data/Batch1\\\\FINWIRE1992Q3',\n",
       " 'src/data/Batch1\\\\FINWIRE1992Q4',\n",
       " 'src/data/Batch1\\\\FINWIRE1993Q1',\n",
       " 'src/data/Batch1\\\\FINWIRE1993Q2',\n",
       " 'src/data/Batch1\\\\FINWIRE1993Q3',\n",
       " 'src/data/Batch1\\\\FINWIRE1993Q4',\n",
       " 'src/data/Batch1\\\\FINWIRE1994Q1',\n",
       " 'src/data/Batch1\\\\FINWIRE1994Q2',\n",
       " 'src/data/Batch1\\\\FINWIRE1994Q3',\n",
       " 'src/data/Batch1\\\\FINWIRE1994Q4',\n",
       " 'src/data/Batch1\\\\FINWIRE1995Q1',\n",
       " 'src/data/Batch1\\\\FINWIRE1995Q2',\n",
       " 'src/data/Batch1\\\\FINWIRE1995Q3',\n",
       " 'src/data/Batch1\\\\FINWIRE1995Q4',\n",
       " 'src/data/Batch1\\\\FINWIRE1996Q1',\n",
       " 'src/data/Batch1\\\\FINWIRE1996Q2',\n",
       " 'src/data/Batch1\\\\FINWIRE1996Q3',\n",
       " 'src/data/Batch1\\\\FINWIRE1996Q4',\n",
       " 'src/data/Batch1\\\\FINWIRE1997Q1',\n",
       " 'src/data/Batch1\\\\FINWIRE1997Q2',\n",
       " 'src/data/Batch1\\\\FINWIRE1997Q3',\n",
       " 'src/data/Batch1\\\\FINWIRE1997Q4',\n",
       " 'src/data/Batch1\\\\FINWIRE1998Q1',\n",
       " 'src/data/Batch1\\\\FINWIRE1998Q2',\n",
       " 'src/data/Batch1\\\\FINWIRE1998Q3',\n",
       " 'src/data/Batch1\\\\FINWIRE1998Q4',\n",
       " 'src/data/Batch1\\\\FINWIRE1999Q1',\n",
       " 'src/data/Batch1\\\\FINWIRE1999Q2',\n",
       " 'src/data/Batch1\\\\FINWIRE1999Q3',\n",
       " 'src/data/Batch1\\\\FINWIRE1999Q4',\n",
       " 'src/data/Batch1\\\\FINWIRE2000Q1',\n",
       " 'src/data/Batch1\\\\FINWIRE2000Q2',\n",
       " 'src/data/Batch1\\\\FINWIRE2000Q3',\n",
       " 'src/data/Batch1\\\\FINWIRE2000Q4',\n",
       " 'src/data/Batch1\\\\FINWIRE2001Q1',\n",
       " 'src/data/Batch1\\\\FINWIRE2001Q2',\n",
       " 'src/data/Batch1\\\\FINWIRE2001Q3',\n",
       " 'src/data/Batch1\\\\FINWIRE2001Q4',\n",
       " 'src/data/Batch1\\\\FINWIRE2002Q1',\n",
       " 'src/data/Batch1\\\\FINWIRE2002Q2',\n",
       " 'src/data/Batch1\\\\FINWIRE2002Q3',\n",
       " 'src/data/Batch1\\\\FINWIRE2002Q4',\n",
       " 'src/data/Batch1\\\\FINWIRE2003Q1',\n",
       " 'src/data/Batch1\\\\FINWIRE2003Q2',\n",
       " 'src/data/Batch1\\\\FINWIRE2003Q3',\n",
       " 'src/data/Batch1\\\\FINWIRE2003Q4',\n",
       " 'src/data/Batch1\\\\FINWIRE2004Q1',\n",
       " 'src/data/Batch1\\\\FINWIRE2004Q2',\n",
       " 'src/data/Batch1\\\\FINWIRE2004Q3',\n",
       " 'src/data/Batch1\\\\FINWIRE2004Q4',\n",
       " 'src/data/Batch1\\\\FINWIRE2005Q1',\n",
       " 'src/data/Batch1\\\\FINWIRE2005Q2',\n",
       " 'src/data/Batch1\\\\FINWIRE2005Q3',\n",
       " 'src/data/Batch1\\\\FINWIRE2005Q4',\n",
       " 'src/data/Batch1\\\\FINWIRE2006Q1',\n",
       " 'src/data/Batch1\\\\FINWIRE2006Q2',\n",
       " 'src/data/Batch1\\\\FINWIRE2006Q3',\n",
       " 'src/data/Batch1\\\\FINWIRE2006Q4',\n",
       " 'src/data/Batch1\\\\FINWIRE2007Q1',\n",
       " 'src/data/Batch1\\\\FINWIRE2007Q2',\n",
       " 'src/data/Batch1\\\\FINWIRE2007Q3',\n",
       " 'src/data/Batch1\\\\FINWIRE2007Q4',\n",
       " 'src/data/Batch1\\\\FINWIRE2008Q1',\n",
       " 'src/data/Batch1\\\\FINWIRE2008Q2',\n",
       " 'src/data/Batch1\\\\FINWIRE2008Q3',\n",
       " 'src/data/Batch1\\\\FINWIRE2008Q4',\n",
       " 'src/data/Batch1\\\\FINWIRE2009Q1',\n",
       " 'src/data/Batch1\\\\FINWIRE2009Q2',\n",
       " 'src/data/Batch1\\\\FINWIRE2009Q3',\n",
       " 'src/data/Batch1\\\\FINWIRE2009Q4',\n",
       " 'src/data/Batch1\\\\FINWIRE2010Q1',\n",
       " 'src/data/Batch1\\\\FINWIRE2010Q2',\n",
       " 'src/data/Batch1\\\\FINWIRE2010Q3',\n",
       " 'src/data/Batch1\\\\FINWIRE2010Q4',\n",
       " 'src/data/Batch1\\\\FINWIRE2011Q1',\n",
       " 'src/data/Batch1\\\\FINWIRE2011Q2',\n",
       " 'src/data/Batch1\\\\FINWIRE2011Q3',\n",
       " 'src/data/Batch1\\\\FINWIRE2011Q4',\n",
       " 'src/data/Batch1\\\\FINWIRE2012Q1',\n",
       " 'src/data/Batch1\\\\FINWIRE2012Q2',\n",
       " 'src/data/Batch1\\\\FINWIRE2012Q3',\n",
       " 'src/data/Batch1\\\\FINWIRE2012Q4',\n",
       " 'src/data/Batch1\\\\FINWIRE2013Q1',\n",
       " 'src/data/Batch1\\\\FINWIRE2013Q2',\n",
       " 'src/data/Batch1\\\\FINWIRE2013Q3',\n",
       " 'src/data/Batch1\\\\FINWIRE2013Q4',\n",
       " 'src/data/Batch1\\\\FINWIRE2014Q1',\n",
       " 'src/data/Batch1\\\\FINWIRE2014Q2',\n",
       " 'src/data/Batch1\\\\FINWIRE2014Q3',\n",
       " 'src/data/Batch1\\\\FINWIRE2014Q4',\n",
       " 'src/data/Batch1\\\\FINWIRE2015Q1',\n",
       " 'src/data/Batch1\\\\FINWIRE2015Q2',\n",
       " 'src/data/Batch1\\\\FINWIRE2015Q3',\n",
       " 'src/data/Batch1\\\\FINWIRE2015Q4',\n",
       " 'src/data/Batch1\\\\FINWIRE2016Q1',\n",
       " 'src/data/Batch1\\\\FINWIRE2016Q2',\n",
       " 'src/data/Batch1\\\\FINWIRE2016Q3',\n",
       " 'src/data/Batch1\\\\FINWIRE2016Q4',\n",
       " 'src/data/Batch1\\\\FINWIRE2017Q1',\n",
       " 'src/data/Batch1\\\\FINWIRE2017Q2',\n",
       " 'src/data/Batch1\\\\FINWIRE2017Q3']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "def find_finwire_files(folder_path):\n",
    "    \"\"\"\n",
    "    Traverses a folder recursively and finds files matching the pattern\n",
    "    FINWIRE<YYYY>Q<Q> (e.g., FINWIRE2016Q3, FINWIRE2016Q4.txt).\n",
    "\n",
    "    It specifically looks for filenames where the part *before* the extension\n",
    "    exactly matches the pattern 'FINWIRE' followed by 4 digits (year),\n",
    "    'Q', and 1 digit (quarter). Files with additional suffixes before the\n",
    "    extension (like '_audit' in FINWIRE1967Q2_audit.csv) are skipped.\n",
    "\n",
    "    Args:\n",
    "        folder_path (str): The path to the folder to traverse.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of full paths to the matching files.\n",
    "               Returns an empty list if the folder doesn't exist or no\n",
    "               matching files are found.\n",
    "    \"\"\"\n",
    "    matching_files = []\n",
    "\n",
    "    # Regex pattern:\n",
    "    # ^        - anchor to the start of the string\n",
    "    # FINWIRE  - literal string\n",
    "    # \\d{4}    - exactly 4 digits (for the year)\n",
    "    # Q        - literal character 'Q'\n",
    "    # \\d       - exactly 1 digit (for the quarter)\n",
    "    # $        - anchor to the end of the string\n",
    "    # This pattern ensures the base name matches exactly.\n",
    "    pattern = re.compile(r\"^FINWIRE\\d{4}Q\\d$\")\n",
    "\n",
    "    # Check if the folder path exists\n",
    "    if not os.path.isdir(folder_path):\n",
    "        print(f\"Warning: Folder not found at {folder_path}\")\n",
    "        return matching_files\n",
    "\n",
    "    # os.walk traverses the directory tree (root, dirs, files)\n",
    "    for root, _, files in os.walk(folder_path):\n",
    "        for filename in files:\n",
    "            # Split the filename into the base name and the extension\n",
    "            base_name, _ = os.path.splitext(filename)\n",
    "\n",
    "            # Check if the base name matches the compiled regex pattern\n",
    "            if pattern.match(base_name):\n",
    "                # If it matches, construct the full path and add it to the list\n",
    "                full_path = os.path.join(root, filename)\n",
    "                matching_files.append(full_path)\n",
    "\n",
    "    return matching_files\n",
    "\n",
    "find_finwire_files(src_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQL query successfully written to 'C:\\lopu-kg-test\\project\\src\\main\\sql_for_pipelines\\1_wh_db_stage.FinWire.sql'.\n",
      "src/data/Batch1\\FINWIRE1967Q1 --DONE--\n"
     ]
    }
   ],
   "source": [
    "# siin pooleli\n",
    "\n",
    "src_folder = 'src/data/Batch1'\n",
    "list_of_finwire_files = find_finwire_files(src_folder)\n",
    "# file_path = os.path.join(src_folder, \"FINWIRE2016Q3\")\n",
    "\n",
    "\n",
    "file_path = list_of_finwire_files[1]\n",
    "fin_wire_sql = f\"\"\" \n",
    "    INSERT INTO wh_db_stage.FinWire\n",
    "    SELECT\n",
    "        CASE\n",
    "            WHEN SUBSTR(column0, 16, 3) = 'FIN' THEN\n",
    "                CASE\n",
    "                    WHEN TRY_CAST(TRIM(SUBSTR(column0, 187, 60)) AS BIGINT) IS NOT NULL THEN 'FIN_COMPANYID'\n",
    "                    ELSE 'FIN_NAME'\n",
    "                END\n",
    "            ELSE SUBSTR(column0, 16, 3)\n",
    "        END AS rectype,\n",
    "        STRPTIME(SUBSTR(column0, 1, 8), '%Y%m%d') AS recdate,\n",
    "        SUBSTR(column0, 19) AS value\n",
    "    FROM read_csv_auto('{file_path}', HEADER=FALSE, filename=false, all_varchar=true)\n",
    "    \"\"\"\n",
    "\n",
    "for file_path in list_of_finwire_files:\n",
    " #   file_path = os.path.join(src_folder, file)\n",
    "    # õige\n",
    "    con.sql(fin_wire_sql)\n",
    "    save_sql_to_file(fin_wire_sql, \"wh_db_stage.FinWire\")\n",
    "    print(file_path, \"--DONE--\")\n",
    "    break # limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQL query successfully written to 'C:\\lopu-kg-test\\project\\src\\main\\sql_for_pipelines\\2_wh_db.DimCompany.sql'.\n"
     ]
    }
   ],
   "source": [
    "# õige\n",
    "dimcompany_insert_sql = \"\"\"INSERT INTO wh_db.DimCompany\n",
    "WITH cmp AS (\n",
    "    SELECT\n",
    "        recdate,\n",
    "        TRIM(SUBSTR(value, 1, 60)) AS CompanyName,\n",
    "        TRIM(SUBSTR(value, 61, 10)) AS CIK,\n",
    "        TRIM(SUBSTR(value, 71, 4)) AS Status,\n",
    "        TRIM(SUBSTR(value, 75, 2)) AS IndustryID,\n",
    "        TRIM(SUBSTR(value, 77, 4)) AS SPrating,\n",
    "        TRY_CAST(TRY_CAST(SUBSTRING(value, 81, 8) AS TIMESTAMP) AS DATE) AS FoundingDate,\n",
    "        TRIM(SUBSTR(value, 89, 80)) AS AddrLine1,\n",
    "        TRIM(SUBSTR(value, 169, 80)) AS AddrLine2,\n",
    "        TRIM(SUBSTR(value, 249, 12)) AS PostalCode,\n",
    "        TRIM(SUBSTR(value, 261, 25)) AS City,\n",
    "        TRIM(SUBSTR(value, 286, 20)) AS StateProvince,\n",
    "        TRIM(SUBSTR(value, 306, 24)) AS Country,\n",
    "        TRIM(SUBSTR(value, 330, 46)) AS CEOname,\n",
    "        TRIM(SUBSTR(value, 376, 150)) AS Description\n",
    "    FROM wh_db_stage.FinWire\n",
    "    WHERE rectype = 'CMP'\n",
    ")\n",
    "SELECT\n",
    "    CAST(strftime(effectivedate, '%Y%m%d') || companyid AS BIGINT) AS sk_companyid,\n",
    "    companyid,\n",
    "    status,\n",
    "    name,\n",
    "    industry,\n",
    "    sprating,\n",
    "    islowgrade,\n",
    "    ceo,\n",
    "    addressline1,\n",
    "    addressline2,\n",
    "    postalcode,\n",
    "    city,\n",
    "    stateprov,\n",
    "    country,\n",
    "    description,\n",
    "    foundingdate,\n",
    "    CASE WHEN enddate = '9999-12-31'::DATE THEN TRUE ELSE FALSE END AS iscurrent,\n",
    "    batchid,\n",
    "    effectivedate,\n",
    "    enddate\n",
    "FROM (\n",
    "    SELECT\n",
    "        CAST(cik AS BIGINT) AS companyid,\n",
    "        CASE cmp.status\n",
    "            WHEN 'ACTV' THEN 'Active'\n",
    "            WHEN 'CMPT' THEN 'Completed'\n",
    "            WHEN 'CNCL' THEN 'Canceled'\n",
    "            WHEN 'PNDG' THEN 'Pending'\n",
    "            WHEN 'SBMT' THEN 'Submitted'\n",
    "            WHEN 'INAC' THEN 'Inactive'\n",
    "            ELSE NULL -- or a default value, if needed\n",
    "        END AS status,\n",
    "        CompanyName AS name,\n",
    "        ind.in_name AS industry,\n",
    "        CASE\n",
    "            WHEN SPrating IN ('AAA', 'AA', 'AA+', 'AA-', 'A', 'A+', 'A-', 'BBB', 'BBB+', 'BBB-', 'BB', 'BB+', 'BB-', 'B', 'B+', 'B-', 'CCC', 'CCC+', 'CCC-', 'CC', 'C', 'D') THEN SPrating\n",
    "            ELSE NULL::VARCHAR\n",
    "        END AS sprating,\n",
    "        CASE\n",
    "            WHEN SPrating IN ('AAA', 'AA', 'A', 'AA+', 'A+', 'AA-', 'A-', 'BBB', 'BBB+', 'BBB-') THEN FALSE\n",
    "            WHEN SPrating IN ('BB', 'B', 'CCC', 'CC', 'C', 'D', 'BB+', 'B+', 'CCC+', 'BB-', 'B-', 'CCC-') THEN TRUE\n",
    "            ELSE NULL::BOOLEAN\n",
    "        END AS islowgrade,\n",
    "        CEOname AS ceo,\n",
    "        AddrLine1 AS addressline1,\n",
    "        AddrLine2 AS addressline2,\n",
    "        PostalCode AS postalcode,\n",
    "        City AS city,\n",
    "        StateProvince AS stateprov,\n",
    "        Country AS country,\n",
    "        Description AS description,\n",
    "        FoundingDate AS foundingdate,\n",
    "        1 AS batchid,\n",
    "        recdate AS effectivedate,\n",
    "        COALESCE(\n",
    "            LEAD(try_cast(recdate AS DATE)) OVER (PARTITION BY cik ORDER BY recdate),\n",
    "            try_cast('9999-12-31' AS DATE)\n",
    "        ) AS enddate\n",
    "    FROM cmp\n",
    "    JOIN wh_db.industry ind ON cmp.industryid = ind.in_id\n",
    ")\n",
    "WHERE effectivedate < enddate;\n",
    "\"\"\"\n",
    "\n",
    "con.sql(dimcompany_insert_sql)\n",
    "save_sql_to_file(dimcompany_insert_sql, \"wh_db.DimCompany\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQL query successfully written to 'C:\\lopu-kg-test\\project\\src\\main\\sql_for_pipelines\\1_wh_db_stage.ProspectIncremental.sql'.\n"
     ]
    }
   ],
   "source": [
    "src_folder = 'src/data/Batch1'\n",
    "file_path = os.path.join(src_folder, \"Prospect.csv\")\n",
    "batch_number = int(''.join(filter(str.isdigit, os.path.basename(src_folder))))\n",
    "\n",
    "temp_propect = f\"\"\"\n",
    "CREATE OR REPLACE TEMP TABLE temp_propect AS \n",
    "SELECT     *, \n",
    "    {batch_number} AS batchid \n",
    "    FROM read_csv_auto('{file_path}', columns={{\n",
    "    \"agencyid\": \"STRING\",\n",
    "    \"lastname\": \"STRING\",\n",
    "    \"firstname\": \"STRING\",\n",
    "    \"middleinitial\": \"STRING\",\n",
    "    \"gender\": \"STRING\",\n",
    "    \"addressline1\": \"STRING\",\n",
    "    \"addressline2\": \"STRING\",\n",
    "    \"postalcode\": \"STRING\",\n",
    "    \"city\": \"STRING\",\n",
    "    \"state\": \"STRING\",\n",
    "    \"country\": \"STRING\",\n",
    "    \"phone\": \"STRING\",\n",
    "    \"income\": \"INT\",\n",
    "    \"numbercars\": \"INT\",\n",
    "    \"numberchildren\": \"INT\",\n",
    "    \"maritalstatus\": \"STRING\",\n",
    "    \"age\": \"INT\",\n",
    "    \"creditrating\": \"INT\",\n",
    "    \"ownorrentflag\": \"STRING\",\n",
    "    \"employer\": \"STRING\",\n",
    "    \"numbercreditcards\": \"INT\",\n",
    "    \"networth\": \"INT\",\n",
    "}}, header=False);\n",
    "\"\"\"\n",
    "\n",
    "con.sql(temp_propect)\n",
    "save_sql_to_file(temp_propect, \"wh_db_stage.ProspectIncremental\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQL query successfully written to 'C:\\lopu-kg-test\\project\\src\\main\\sql_for_pipelines\\2_wh_db_stage.ProspectIncremental.sql'.\n"
     ]
    }
   ],
   "source": [
    "temp_propect_marketingnameplate = \"\"\"\n",
    "CREATE OR REPLACE TEMP TABLE temp_propect_marketingnameplate AS \n",
    "SELECT\n",
    "    *,\n",
    "    CASE \n",
    "        WHEN LENGTH(\n",
    "            CONCAT(\n",
    "                CASE WHEN networth > 1000000 OR income > 200000 THEN 'HighValue+' ELSE '' END,\n",
    "                CASE WHEN numberchildren > 3 OR numbercreditcards > 5 THEN 'Expenses+' ELSE '' END,\n",
    "                CASE WHEN age > 45 THEN 'Boomer+' ELSE '' END,\n",
    "                CASE WHEN income < 50000 OR creditrating < 600 OR networth < 100000 THEN 'MoneyAlert+' ELSE '' END,\n",
    "                CASE WHEN numbercars > 3 OR numbercreditcards > 7 THEN 'Spender+' ELSE '' END,\n",
    "                CASE WHEN age < 25 AND networth > 1000000 THEN 'Inherited+' ELSE '' END\n",
    "            )\n",
    "        ) > 0 \n",
    "        THEN LEFT(\n",
    "            CONCAT(\n",
    "                CASE WHEN networth > 1000000 OR income > 200000 THEN 'HighValue+' ELSE '' END,\n",
    "                CASE WHEN numberchildren > 3 OR numbercreditcards > 5 THEN 'Expenses+' ELSE '' END,\n",
    "                CASE WHEN age > 45 THEN 'Boomer+' ELSE '' END,\n",
    "                CASE WHEN income < 50000 OR creditrating < 600 OR networth < 100000 THEN 'MoneyAlert+' ELSE '' END,\n",
    "                CASE WHEN numbercars > 3 OR numbercreditcards > 7 THEN 'Spender+' ELSE '' END,\n",
    "                CASE WHEN age < 25 AND networth > 1000000 THEN 'Inherited+' ELSE '' END\n",
    "            ),\n",
    "            LENGTH(\n",
    "                CONCAT(\n",
    "                    CASE WHEN networth > 1000000 OR income > 200000 THEN 'HighValue+' ELSE '' END,\n",
    "                    CASE WHEN numberchildren > 3 OR numbercreditcards > 5 THEN 'Expenses+' ELSE '' END,\n",
    "                    CASE WHEN age > 45 THEN 'Boomer+' ELSE '' END,\n",
    "                    CASE WHEN income < 50000 OR creditrating < 600 OR networth < 100000 THEN 'MoneyAlert+' ELSE '' END,\n",
    "                    CASE WHEN numbercars > 3 OR numbercreditcards > 7 THEN 'Spender+' ELSE '' END,\n",
    "                    CASE WHEN age < 25 AND networth > 1000000 THEN 'Inherited+' ELSE '' END\n",
    "                )\n",
    "            ) - 1\n",
    "        )\n",
    "        ELSE NULL \n",
    "    END AS marketingnameplate\n",
    "FROM temp_propect;\n",
    "\"\"\"\n",
    "\n",
    "con.sql(temp_propect_marketingnameplate)\n",
    "save_sql_to_file(temp_propect_marketingnameplate, \"wh_db_stage.ProspectIncremental\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## täpselt ei tea, mille järgi tuvastada ridu - st kas agency_id, firstname_lastname piisab\n",
    "con.sql(\"\"\" \n",
    "ALTER TABLE wh_db_stage.ProspectIncremental\n",
    "    ADD CONSTRAINT ProspectIncremental_pk PRIMARY KEY (agencyid, lastname, firstname);\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQL query successfully written to 'C:\\lopu-kg-test\\project\\src\\main\\sql_for_pipelines\\3_wh_db_stage.ProspectIncremental.sql'.\n"
     ]
    }
   ],
   "source": [
    "ProspectIncremental = \"\"\"\n",
    "INSERT INTO wh_db_stage.ProspectIncremental (\n",
    "    agencyid, lastname, firstname, middleinitial, gender, addressline1, \n",
    "    addressline2, postalcode, city, state, country, phone, income, \n",
    "    numbercars, numberchildren, maritalstatus, age, creditrating, \n",
    "    ownorrentflag, employer, numbercreditcards, networth, \n",
    "    marketingnameplate, recordbatchid, batchid\n",
    ")\n",
    "SELECT\n",
    "    tp.agencyid, tp.lastname, tp.firstname, tp.middleinitial, tp.gender, tp.addressline1, \n",
    "    tp.addressline2, tp.postalcode, tp.city, tp.state, tp.country, tp.phone, tp.income, \n",
    "    tp.numbercars, tp.numberchildren, tp.maritalstatus, tp.age, tp.creditrating, \n",
    "    tp.ownorrentflag, tp.employer, tp.numbercreditcards, tp.networth, \n",
    "    tp.marketingnameplate, tp.batchid, tp.batchid\n",
    "FROM temp_propect_marketingnameplate AS tp\n",
    "ON CONFLICT (agencyid, lastname, firstname) DO UPDATE SET\n",
    "    middleinitial = excluded.middleinitial,\n",
    "    gender = excluded.gender,\n",
    "    addressline1 = excluded.addressline1,\n",
    "    addressline2 = excluded.addressline2,\n",
    "    postalcode = excluded.postalcode,\n",
    "    city = excluded.city,\n",
    "    state = excluded.state,\n",
    "    country = excluded.country,\n",
    "    phone = excluded.phone,\n",
    "    income = excluded.income,\n",
    "    numbercars = excluded.numbercars,\n",
    "    numberchildren = excluded.numberchildren,\n",
    "    maritalstatus = excluded.maritalstatus,\n",
    "    age = excluded.age,\n",
    "    creditrating = excluded.creditrating,\n",
    "    ownorrentflag = excluded.ownorrentflag,\n",
    "    employer = excluded.employer,\n",
    "    numbercreditcards = excluded.numbercreditcards,\n",
    "    networth = excluded.networth,\n",
    "    marketingnameplate = excluded.marketingnameplate,\n",
    "    recordbatchid = excluded.batchid;\n",
    "\"\"\"\n",
    "con.sql(ProspectIncremental)\n",
    "save_sql_to_file(ProspectIncremental, \"wh_db_stage.ProspectIncremental\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "┌────────────┬───────────┬──────────┬─────────────┬───────────────────────────────────────────────┬───────────┬──────────┬──────────┬───────────┬───────────────┬─────────┬──────┬────────────┬──────────────────┬──────────────┬────────────┬───────────────┬───────────┬──────────────────────────┬────────────────┬──────────┬───────────────────┬───────────────────────────┬───────────────────────────────┬───────────┬───────────┬─────────────────────┬────────────┐\n",
       "│ customerid │ accountid │ brokerid │    taxid    │                  accountdesc                  │ taxstatus │  status  │ lastname │ firstname │ middleinitial │ gender  │ tier │    dob     │   addressline1   │ addressline2 │ postalcode │     city      │ stateprov │         country          │     phone1     │  phone2  │      phone3       │          email1           │            email2             │ lcl_tx_id │ nat_tx_id │      update_ts      │ ActionType │\n",
       "│   int64    │   int64   │  int64   │   varchar   │                    varchar                    │   int8    │ varchar  │ varchar  │  varchar  │    varchar    │ varchar │ int8 │    date    │     varchar      │   varchar    │  varchar   │    varchar    │  varchar  │         varchar          │    varchar     │ varchar  │      varchar      │          varchar          │            varchar            │  varchar  │  varchar  │      timestamp      │  varchar   │\n",
       "├────────────┼───────────┼──────────┼─────────────┼───────────────────────────────────────────────┼───────────┼──────────┼──────────┼───────────┼───────────────┼─────────┼──────┼────────────┼──────────────────┼──────────────┼────────────┼───────────────┼───────────┼──────────────────────────┼────────────────┼──────────┼───────────────────┼───────────────────────────┼───────────────────────────────┼───────────┼───────────┼─────────────────────┼────────────┤\n",
       "│         20 │        20 │    23517 │ 824-42-1232 │ FXHiaOLVYyWUGnRkdSXFJTTlkLDcGWtVQAMJZ         │         1 │ Active   │ Coppins  │ Drucill   │ NULL          │ M       │    3 │ 2008-11-07 │ 911 Topple Drive │ NULL         │ 21707      │ Winston-Salem │ OK        │ Canada                   │ (403) 386-7631 │ 964-5176 │ 057-4032          │ Drucill.Coppins@yahoo.com │ Drucill.Coppins@spamavert.com │ NB7       │ AB5       │ 2007-07-09 13:16:04 │ NEW        │\n",
       "│         20 │       225 │    17367 │ NULL        │ dfVfLHXGTjNdVElVuqbLTqJjInRVFqwIoTdnRPFiCUQES │         1 │ Active   │ NULL     │ NULL      │ NULL          │ NULL    │ NULL │ NULL       │ NULL             │ NULL         │ NULL       │ NULL          │ NULL      │ NULL                     │ NULL           │ NULL     │ NULL              │ NULL                      │ NULL                          │ NULL      │ NULL      │ 2007-08-24 05:19:19 │ ADDACCT    │\n",
       "│         20 │      NULL │     NULL │ NULL        │ NULL                                          │      NULL │ Active   │ NULL     │ NULL      │ NULL          │ NULL    │    3 │ NULL       │ 14791 Bluff East │ NULL         │ M5D 1Y2    │ Orange        │ OR        │ United States of America │ 389-1326       │ 632-1025 │ +1 (489) 856-5017 │ Drucill.Coppins@post.com  │ NULL                          │ NULL      │ NULL      │ 2007-08-31 13:06:49 │ UPDCUST    │\n",
       "│         20 │      NULL │     NULL │ NULL        │ NULL                                          │      NULL │ Inactive │ NULL     │ NULL      │ NULL          │ NULL    │ NULL │ NULL       │ NULL             │ NULL         │ NULL       │ NULL          │ NULL      │ NULL                     │ NULL           │ NULL     │ NULL              │ NULL                      │ NULL                          │ NULL      │ NULL      │ 2007-09-06 01:42:46 │ INACT      │\n",
       "│         20 │        20 │     NULL │ NULL        │ NULL                                          │      NULL │ Inactive │ NULL     │ NULL      │ NULL          │ NULL    │ NULL │ NULL       │ NULL             │ NULL         │ NULL       │ NULL          │ NULL      │ NULL                     │ NULL           │ NULL     │ NULL              │ NULL                      │ NULL                          │ NULL      │ NULL      │ 2010-04-21 17:55:36 │ CLOSEACCT  │\n",
       "└────────────┴───────────┴──────────┴─────────────┴───────────────────────────────────────────────┴───────────┴──────────┴──────────┴───────────┴───────────────┴─────────┴──────┴────────────┴──────────────────┴──────────────┴────────────┴───────────────┴───────────┴──────────────────────────┴────────────────┴──────────┴───────────────────┴───────────────────────────┴───────────────────────────────┴───────────┴───────────┴─────────────────────┴────────────┘"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con.sql(\"select * from wh_db_stage.CustomerMgmt where customerid = 20\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "┌────────────┬───────────┬──────────┬─────────────┬───────────────────────────────────────────────┬───────────┬──────────┬──────────┬───────────┬───────────────┬─────────┬──────┬────────────┬──────────────────┬──────────────┬────────────┬───────────────┬───────────┬──────────────────────────┬────────────────┬──────────┬───────────────────┬───────────────────────────┬───────────────────────────────┬───────────┬───────────┬─────────────────────┬────────────┬─────────┬────────────────────────────────────────────┬─────────┐\n",
       "│ customerid │ accountid │ brokerid │    taxid    │                  accountdesc                  │ taxstatus │  status  │ lastname │ firstname │ middleinitial │ gender  │ tier │    dob     │   addressline1   │ addressline2 │ postalcode │     city      │ stateprov │         country          │     phone1     │  phone2  │      phone3       │          email1           │            email2             │ lcl_tx_id │ nat_tx_id │      update_ts      │ ActionType │  tx_id  │                  tx_name                   │ tx_rate │\n",
       "│   int64    │   int64   │  int64   │   varchar   │                    varchar                    │   int8    │ varchar  │ varchar  │  varchar  │    varchar    │ varchar │ int8 │    date    │     varchar      │   varchar    │  varchar   │    varchar    │  varchar  │         varchar          │    varchar     │ varchar  │      varchar      │          varchar          │            varchar            │  varchar  │  varchar  │      timestamp      │  varchar   │ varchar │                  varchar                   │  float  │\n",
       "├────────────┼───────────┼──────────┼─────────────┼───────────────────────────────────────────────┼───────────┼──────────┼──────────┼───────────┼───────────────┼─────────┼──────┼────────────┼──────────────────┼──────────────┼────────────┼───────────────┼───────────┼──────────────────────────┼────────────────┼──────────┼───────────────────┼───────────────────────────┼───────────────────────────────┼───────────┼───────────┼─────────────────────┼────────────┼─────────┼────────────────────────────────────────────┼─────────┤\n",
       "│         20 │        20 │    23517 │ 824-42-1232 │ FXHiaOLVYyWUGnRkdSXFJTTlkLDcGWtVQAMJZ         │         1 │ Active   │ Coppins  │ Drucill   │ NULL          │ M       │    3 │ 2008-11-07 │ 911 Topple Drive │ NULL         │ 21707      │ Winston-Salem │ OK        │ Canada                   │ (403) 386-7631 │ 964-5176 │ 057-4032          │ Drucill.Coppins@yahoo.com │ Drucill.Coppins@spamavert.com │ NB7       │ AB5       │ 2007-07-09 13:16:04 │ NEW        │ AB5     │ Alberta Income Tax for doctors and lawyers │    0.36 │\n",
       "│         20 │       225 │    17367 │ NULL        │ dfVfLHXGTjNdVElVuqbLTqJjInRVFqwIoTdnRPFiCUQES │         1 │ Active   │ NULL     │ NULL      │ NULL          │ NULL    │ NULL │ NULL       │ NULL             │ NULL         │ NULL       │ NULL          │ NULL      │ NULL                     │ NULL           │ NULL     │ NULL              │ NULL                      │ NULL                          │ NULL      │ NULL      │ 2007-08-24 05:19:19 │ ADDACCT    │ NULL    │ NULL                                       │    NULL │\n",
       "│         20 │      NULL │     NULL │ NULL        │ NULL                                          │      NULL │ Active   │ NULL     │ NULL      │ NULL          │ NULL    │    3 │ NULL       │ 14791 Bluff East │ NULL         │ M5D 1Y2    │ Orange        │ OR        │ United States of America │ 389-1326       │ 632-1025 │ +1 (489) 856-5017 │ Drucill.Coppins@post.com  │ NULL                          │ NULL      │ NULL      │ 2007-08-31 13:06:49 │ UPDCUST    │ NULL    │ NULL                                       │    NULL │\n",
       "│         20 │      NULL │     NULL │ NULL        │ NULL                                          │      NULL │ Inactive │ NULL     │ NULL      │ NULL          │ NULL    │ NULL │ NULL       │ NULL             │ NULL         │ NULL       │ NULL          │ NULL      │ NULL                     │ NULL           │ NULL     │ NULL              │ NULL                      │ NULL                          │ NULL      │ NULL      │ 2007-09-06 01:42:46 │ INACT      │ NULL    │ NULL                                       │    NULL │\n",
       "│         20 │        20 │     NULL │ NULL        │ NULL                                          │      NULL │ Inactive │ NULL     │ NULL      │ NULL          │ NULL    │ NULL │ NULL       │ NULL             │ NULL         │ NULL       │ NULL          │ NULL      │ NULL                     │ NULL           │ NULL     │ NULL              │ NULL                      │ NULL                          │ NULL      │ NULL      │ 2010-04-21 17:55:36 │ CLOSEACCT  │ NULL    │ NULL                                       │    NULL │\n",
       "└────────────┴───────────┴──────────┴─────────────┴───────────────────────────────────────────────┴───────────┴──────────┴──────────┴───────────┴───────────────┴─────────┴──────┴────────────┴──────────────────┴──────────────┴────────────┴───────────────┴───────────┴──────────────────────────┴────────────────┴──────────┴───────────────────┴───────────────────────────┴───────────────────────────────┴───────────┴───────────┴─────────────────────┴────────────┴─────────┴────────────────────────────────────────────┴─────────┘"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con.sql(\"\"\" \n",
    "select distinct * from \n",
    "wh_db_stage.CustomerMgmt a\n",
    "LEFT \n",
    "join wh_db.TaxRate b on\n",
    "        a.nat_tx_id  = b.TX_ID\n",
    "where a.customerid = 20\n",
    "order by update_ts asc\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQL query successfully written to 'C:\\lopu-kg-test\\project\\src\\main\\sql_for_pipelines\\1_wh_db.DimCustomer.sql'.\n"
     ]
    }
   ],
   "source": [
    "# Cust historical pipeline\n",
    "\n",
    "customers = \"\"\" \n",
    "CREATE OR REPLACE TEMP TABLE customers AS\n",
    "  SELECT\n",
    "    customerid,\n",
    "    taxid,\n",
    "    status,\n",
    "    lastname,\n",
    "    firstname,\n",
    "    middleinitial,\n",
    "    gender,\n",
    "    tier,\n",
    "    dob,\n",
    "    addressline1,\n",
    "    addressline2,\n",
    "    postalcode,\n",
    "    city,\n",
    "    stateprov,\n",
    "    country,\n",
    "    phone1,\n",
    "    phone2,\n",
    "    phone3,\n",
    "    email1,\n",
    "    email2,\n",
    "    lcl_tx_id,\n",
    "    nat_tx_id,\n",
    "    1 batchid,\n",
    "    update_ts\n",
    "  FROM\n",
    "    wh_db_stage.CustomerMgmt c\n",
    "  WHERE\n",
    "    ActionType in ('NEW', 'INACT', 'UPDCUST')\n",
    "\"\"\"\n",
    "\n",
    "con.sql(customers)\n",
    "save_sql_to_file(customers, \"wh_db.DimCustomer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQL query successfully written to 'C:\\lopu-kg-test\\project\\src\\main\\sql_for_pipelines\\2_wh_db.DimCustomer.sql'.\n"
     ]
    }
   ],
   "source": [
    "customers_final = \"\"\"CREATE OR REPLACE TEMP TABLE customers_final AS\n",
    "SELECT\n",
    "    customerid,\n",
    "    COALESCE(taxid, last_value(taxid ORDER BY update_ts DESC) OVER w) AS taxid,\n",
    "    status,\n",
    "    COALESCE(lastname, last_value(lastname ORDER BY update_ts DESC) OVER w) AS lastname,\n",
    "    COALESCE(firstname, last_value(firstname ORDER BY update_ts DESC) OVER w) AS firstname,\n",
    "    COALESCE(middleinitial, last_value(middleinitial ORDER BY update_ts DESC) OVER w) AS middleinitial,\n",
    "    COALESCE(gender, last_value(gender ORDER BY update_ts DESC) OVER w) AS gender,\n",
    "    COALESCE(tier, last_value(tier ORDER BY update_ts DESC) OVER w) AS tier,\n",
    "    COALESCE(dob, last_value(dob ORDER BY update_ts DESC) OVER w) AS dob,\n",
    "    COALESCE(addressline1, last_value(addressline1 ORDER BY update_ts DESC) OVER w) AS addressline1,\n",
    "    COALESCE(addressline2, last_value(addressline2 ORDER BY update_ts DESC) OVER w) AS addressline2,\n",
    "    COALESCE(postalcode, last_value(postalcode ORDER BY update_ts DESC) OVER w) AS postalcode,\n",
    "    COALESCE(CITY, last_value(CITY ORDER BY update_ts DESC) OVER w) AS CITY,\n",
    "    COALESCE(stateprov, last_value(stateprov ORDER BY update_ts DESC) OVER w) AS stateprov,\n",
    "    COALESCE(country, last_value(country ORDER BY update_ts DESC) OVER w) AS country,\n",
    "    COALESCE(phone1, last_value(phone1 ORDER BY update_ts DESC) OVER w) AS phone1,\n",
    "    COALESCE(phone2, last_value(phone2 ORDER BY update_ts DESC) OVER w) AS phone2,\n",
    "    COALESCE(phone3, last_value(phone3 ORDER BY update_ts DESC) OVER w) AS phone3,\n",
    "    COALESCE(email1, last_value(email1 ORDER BY update_ts DESC) OVER w) AS email1,\n",
    "    COALESCE(email2, last_value(email2 ORDER BY update_ts DESC) OVER w) AS email2,\n",
    "    COALESCE(LCL_TX_ID, last_value(LCL_TX_ID ORDER BY update_ts DESC) OVER w) AS LCL_TX_ID,\n",
    "    COALESCE(NAT_TX_ID, last_value(NAT_TX_ID ORDER BY update_ts DESC) OVER w) AS NAT_TX_ID,\n",
    "    batchid,\n",
    "    CASE \n",
    "        WHEN NULLIF(lead(update_ts) OVER w, NULL) IS NULL THEN 'Y' \n",
    "        ELSE 'N' \n",
    "    END AS iscurrent,\n",
    "    update_ts::DATE AS effectivedate,\n",
    "    COALESCE(lead(update_ts::DATE) OVER w, '9999-12-31'::DATE) AS enddate\n",
    "FROM\n",
    "    customers\n",
    "WINDOW w AS (PARTITION BY customerid ORDER BY update_ts);\"\"\"\n",
    "\n",
    "con.sql(customers_final)\n",
    "save_sql_to_file(customers_final, \"wh_db.DimCustomer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQL query successfully written to 'C:\\lopu-kg-test\\project\\src\\main\\sql_for_pipelines\\3_wh_db.DimCustomer.sql'.\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "dimcustomer = \"\"\"\n",
    "INSERT INTO wh_db.DimCustomer (\n",
    "    sk_customerid,\n",
    "    customerid,\n",
    "    taxid,\n",
    "    status,\n",
    "    lastname,\n",
    "    firstname,\n",
    "    middleinitial,\n",
    "    gender,\n",
    "    tier,\n",
    "    dob,\n",
    "    addressline1,\n",
    "    addressline2,\n",
    "    postalcode,\n",
    "    city,\n",
    "    stateprov,\n",
    "    country,\n",
    "    phone1,\n",
    "    phone2,\n",
    "    phone3,\n",
    "    email1,\n",
    "    email2,\n",
    "    nationaltaxratedesc,\n",
    "    nationaltaxrate,\n",
    "    localtaxratedesc,\n",
    "    localtaxrate,\n",
    "    agencyid,\n",
    "    creditrating,\n",
    "    networth,\n",
    "    marketingnameplate,\n",
    "    iscurrent,\n",
    "    batchid,\n",
    "    effectivedate,\n",
    "    enddate\n",
    ")\n",
    "WITH MaxSK AS (\n",
    "    SELECT COALESCE(MAX(sk_customerid), 0) AS max_sk_customerid\n",
    "    FROM wh_db.DimCustomer\n",
    "),\n",
    "CustomerData AS (\n",
    "    SELECT \n",
    "        c.customerid,\n",
    "        c.taxid,\n",
    "        c.status,\n",
    "        c.lastname,\n",
    "        c.firstname,\n",
    "        c.middleinitial,\n",
    "        c.gender,\n",
    "        c.tier,\n",
    "        c.dob,\n",
    "        c.addressline1,\n",
    "        c.addressline2,\n",
    "        c.postalcode,\n",
    "        c.city,\n",
    "        c.stateprov,\n",
    "        c.country,\n",
    "        c.phone1,\n",
    "        c.phone2,\n",
    "        c.phone3,\n",
    "        c.email1, \n",
    "        c.email2,\n",
    "        r_nat.TX_NAME as nationaltaxratedesc,\n",
    "        r_nat.TX_RATE as nationaltaxrate,\n",
    "        r_lcl.TX_NAME as localtaxratedesc,\n",
    "        r_lcl.TX_RATE as localtaxrate,\n",
    "        p.agencyid,\n",
    "        p.creditrating,\n",
    "        p.networth,\n",
    "        p.marketingnameplate,\n",
    "        c.iscurrent,\n",
    "        c.batchid,\n",
    "        c.effectivedate,\n",
    "        c.enddate \n",
    "    FROM customers_final c\n",
    "    JOIN wh_db.TaxRate r_lcl \n",
    "        ON c.lcl_tx_id = r_lcl.TX_ID\n",
    "    JOIN wh_db.TaxRate r_nat \n",
    "        ON c.nat_tx_id = r_nat.TX_ID\n",
    "    LEFT JOIN wh_db_stage.ProspectIncremental p \n",
    "        ON \n",
    "            UPPER(p.lastname) = UPPER(c.lastname)\n",
    "            AND UPPER(p.firstname) = UPPER(c.firstname)\n",
    "            AND UPPER(p.addressline1) = UPPER(c.addressline1)\n",
    "            AND UPPER(NULLIF(p.addressline2, '')) = UPPER(NULLIF(c.addressline2, ''))\n",
    "            AND UPPER(p.postalcode) = UPPER(c.postalcode)\n",
    "    WHERE c.effectivedate < c.enddate\n",
    ")\n",
    "SELECT \n",
    "    ROW_NUMBER() OVER () + (SELECT max_sk_customerid FROM MaxSK) + 1 AS sk_customerid,\n",
    "    c.customerid,\n",
    "    c.taxid,\n",
    "    c.status,\n",
    "    c.lastname,\n",
    "    c.firstname,\n",
    "    c.middleinitial,\n",
    "    IF(c.gender IN ('M', 'F'), c.gender, 'U') AS gender,\n",
    "    c.tier,\n",
    "    c.dob,\n",
    "    c.addressline1,\n",
    "    c.addressline2,\n",
    "    c.postalcode,\n",
    "    c.city,\n",
    "    c.stateprov,\n",
    "    c.country,\n",
    "    c.phone1,\n",
    "    c.phone2,\n",
    "    c.phone3,\n",
    "    c.email1, \n",
    "    c.email2,\n",
    "    nationaltaxratedesc,\n",
    "    nationaltaxrate,\n",
    "    localtaxratedesc,\n",
    "    localtaxrate,\n",
    "    agencyid,\n",
    "    creditrating,\n",
    "    networth,\n",
    "    marketingnameplate,\n",
    "    iscurrent,\n",
    "    batchid,\n",
    "    effectivedate,\n",
    "    enddate \n",
    "FROM CustomerData c;\n",
    " \"\"\"\n",
    "\n",
    "con.sql(dimcustomer)\n",
    "save_sql_to_file(dimcustomer, \"wh_db.DimCustomer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQL query successfully written to 'C:\\lopu-kg-test\\project\\src\\main\\sql_for_pipelines\\1_wh_db.DimSecurity.sql'.\n"
     ]
    }
   ],
   "source": [
    "# kontrolli kui kõik FINWIRE on laetud\n",
    "DimSecurity = \"\"\" \n",
    "INSERT INTO wh_db.DimSecurity\n",
    "WITH SEC AS (\n",
    "    SELECT\n",
    "        recdate AS effectivedate,\n",
    "        TRIM(SUBSTR(value, 1, 15)) AS Symbol,\n",
    "        TRIM(SUBSTR(value, 16, 6)) AS issue,\n",
    "        TRIM(SUBSTR(value, 22, 4)) AS Status,\n",
    "        TRIM(SUBSTR(value, 26, 70)) AS Name,\n",
    "        TRIM(SUBSTR(value, 96, 6)) AS exchangeid,\n",
    "        TRY_CAST(SUBSTR(value, 102, 13) AS BIGINT) AS sharesoutstanding,\n",
    "        TRY_CAST(STRPTIME(SUBSTR(value, 115, 8), '%Y%m%d') AS DATE) AS firsttrade,\n",
    "        TRY_CAST(STRPTIME(SUBSTR(value, 123, 8), '%Y%m%d') AS DATE) AS firsttradeonexchange,\n",
    "        TRY_CAST(SUBSTR(value, 131, 12) AS DOUBLE) AS Dividend,\n",
    "        TRIM(CASE WHEN  regexp_matches(SUBSTR(value, -10), '^[0-9]+$') THEN  REGEXP_REPLACE(SUBSTR(value, -10), '^0+', '')\n",
    "            ELSE SUBSTR(value, -60)\n",
    "        end) as conameorcik\n",
    "    FROM wh_db_stage.FinWire\n",
    "    WHERE rectype = 'SEC'\n",
    "),\n",
    "dc AS (\n",
    "    SELECT\n",
    "        sk_companyid,\n",
    "        name AS conameorcik,\n",
    "        EffectiveDate,\n",
    "        EndDate\n",
    "    FROM wh_db.DimCompany\n",
    "    UNION ALL\n",
    "    SELECT\n",
    "        sk_companyid,\n",
    "        CAST(companyid AS VARCHAR) AS conameorcik,\n",
    "        EffectiveDate,\n",
    "        EndDate\n",
    "    FROM wh_db.DimCompany\n",
    "),\n",
    "SEC_prep AS (\n",
    "    SELECT\n",
    "        SEC.* EXCLUDE (Status, conameorcik),\n",
    "        COALESCE(TRY_CAST(conameorcik AS BIGINT)::VARCHAR, conameorcik) AS conameorcik,\n",
    "        CASE \n",
    "            WHEN status = 'ACTV' THEN 'Active'\n",
    "            WHEN status = 'CMPT' THEN 'Completed'\n",
    "            WHEN status = 'CNCL' THEN 'Canceled'\n",
    "            WHEN status = 'PNDG' THEN 'Pending'\n",
    "            WHEN status = 'SBMT' THEN 'Submitted'\n",
    "            WHEN status = 'INAC' THEN 'Inactive'\n",
    "            ELSE NULL -- Or handle other cases\n",
    "        END AS status,\n",
    "        COALESCE(\n",
    "            LEAD(effectivedate) OVER (PARTITION BY Symbol ORDER BY effectivedate),\n",
    "            ('9999-12-31')::DATE\n",
    "        ) AS enddate\n",
    "    FROM SEC\n",
    "),\n",
    "        SEC_final AS (\n",
    "    SELECT\n",
    "        SEC.Symbol,\n",
    "        SEC.issue,\n",
    "        SEC.status,\n",
    "        SEC.Name,\n",
    "        SEC.exchangeid,\n",
    "        dc.sk_companyid,\n",
    "        SEC.sharesoutstanding,\n",
    "        SEC.firsttrade,\n",
    "        SEC.firsttradeonexchange,\n",
    "        SEC.Dividend,\n",
    "        CASE WHEN SEC.effectivedate < dc.EffectiveDate THEN dc.EffectiveDate ELSE SEC.effectivedate END AS effectivedate,\n",
    "        CASE WHEN SEC.enddate > dc.EndDate THEN dc.EndDate ELSE SEC.enddate END AS enddate\n",
    "    FROM SEC_prep SEC\n",
    "    JOIN dc\n",
    "        ON SEC.conameorcik = dc.conameorcik\n",
    "        AND SEC.effectivedate < dc.EndDate\n",
    "        AND SEC.enddate > dc.EffectiveDate\n",
    ")\n",
    "SELECT\n",
    "    ROW_NUMBER() OVER () AS sk_securityid,\n",
    "    Symbol,\n",
    "    issue,\n",
    "    status,\n",
    "    Name,\n",
    "    exchangeid,\n",
    "    sk_companyid,\n",
    "    sharesoutstanding,\n",
    "    firsttrade,\n",
    "    firsttradeonexchange,\n",
    "    Dividend,\n",
    "    CASE WHEN enddate = '9999-12-31'::DATE THEN TRUE ELSE FALSE END AS iscurrent,\n",
    "    1 AS batchid,\n",
    "    effectivedate,\n",
    "    enddate\n",
    "FROM SEC_final\n",
    "WHERE effectivedate < enddate;\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "con.sql(DimSecurity)\n",
    "save_sql_to_file(DimSecurity, \"wh_db.DimSecurity\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "┌─────────┬─────────────────────┬─────────┐\n",
       "│ tradeid │       th_dts        │ status  │\n",
       "│  int64  │      timestamp      │ varchar │\n",
       "├─────────┼─────────────────────┼─────────┤\n",
       "│       0 │ 2012-07-07 00:00:47 │ SBMT    │\n",
       "│       0 │ 2012-07-07 00:02:08 │ CMPT    │\n",
       "│       1 │ 2012-07-07 00:06:15 │ SBMT    │\n",
       "│       1 │ 2012-07-07 00:11:02 │ CMPT    │\n",
       "│       2 │ 2012-07-07 00:06:57 │ PNDG    │\n",
       "│       2 │ 2012-07-08 12:07:35 │ SBMT    │\n",
       "│       2 │ 2012-07-08 12:11:23 │ CMPT    │\n",
       "│       3 │ 2012-07-07 00:09:25 │ PNDG    │\n",
       "│       3 │ 2012-09-15 11:35:22 │ SBMT    │\n",
       "│       3 │ 2012-09-15 11:38:32 │ CMPT    │\n",
       "│       · │          ·          │  ·      │\n",
       "│       · │          ·          │  ·      │\n",
       "│       · │          ·          │  ·      │\n",
       "│    3938 │ 2012-07-18 01:46:57 │ PNDG    │\n",
       "│    3938 │ 2012-07-30 02:40:00 │ SBMT    │\n",
       "│    3938 │ 2012-07-30 02:41:57 │ CMPT    │\n",
       "│    3939 │ 2012-07-18 01:51:32 │ PNDG    │\n",
       "│    3939 │ 2012-09-08 16:39:12 │ CNCL    │\n",
       "│    3940 │ 2012-07-18 01:52:23 │ PNDG    │\n",
       "│    3940 │ 2012-09-17 21:51:20 │ SBMT    │\n",
       "│    3940 │ 2012-09-17 21:53:22 │ CMPT    │\n",
       "│    3941 │ 2012-07-18 01:59:06 │ PNDG    │\n",
       "│    3941 │ 2012-09-23 06:03:48 │ SBMT    │\n",
       "├─────────┴─────────────────────┴─────────┤\n",
       "│      ? rows (>9999 rows, 20 shown)      │\n",
       "└─────────────────────────────────────────┘"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_folder = 'src/data/Batch1'\n",
    "file_path = os.path.join(src_folder, \"TradeHistory.txt\")\n",
    "con.sql(f\"\"\" \n",
    "\n",
    "SELECT\n",
    "*\n",
    "FROM read_csv_auto('{file_path}', HEADER=FALSE, filename=false, all_varchar=true, columns = {{\n",
    "    \"tradeid\": \"BIGINT\",\n",
    "    \"th_dts\": \"TIMESTAMP\",\n",
    "    \"status\": \"STRING\"\n",
    "}})\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQL query successfully written to 'C:\\lopu-kg-test\\project\\src\\main\\sql_for_pipelines\\1_wh_db.DimAccount.sql'.\n"
     ]
    }
   ],
   "source": [
    "# DimAccount\n",
    "DimAccount = \"\"\" \n",
    "INSERT INTO wh_db.DimAccount \n",
    "WITH account AS (\n",
    "    SELECT\n",
    "    accountid,\n",
    "    customerid,\n",
    "    accountdesc,\n",
    "    taxstatus,\n",
    "    brokerid,\n",
    "    status,\n",
    "    update_ts,\n",
    "    1 batchid\n",
    "from wh_db_stage.CustomerMgmt\n",
    "where ActionType NOT IN ('UPDCUST', 'INACT')\n",
    "  ),\n",
    "account_final AS (\n",
    "  SELECT\n",
    "    accountid, -- Kept accountid as it's the partitioning key\n",
    "    customerid,\n",
    "    COALESCE(\n",
    "        accountdesc,\n",
    "        last_value(accountdesc) OVER w -- Retained  for correct logic\n",
    "    ) AS accountdesc,\n",
    "    COALESCE(\n",
    "        taxstatus,\n",
    "        last_value(taxstatus)  OVER w -- Retained \n",
    "    ) AS taxstatus,\n",
    "    COALESCE(\n",
    "        brokerid,\n",
    "        last_value(brokerid)  OVER w -- Retained \n",
    "    ) AS brokerid,\n",
    "    COALESCE(\n",
    "        status,\n",
    "        last_value(status)  OVER w -- Retained \n",
    "    ) AS status,\n",
    "    batchid,\n",
    "    CASE\n",
    "        WHEN lead(update_ts) OVER w IS NULL THEN 'Y' -- Check if it's the last record in the partition\n",
    "        ELSE 'N'\n",
    "    END AS iscurrent,\n",
    "    update_ts::DATE AS effectivedate, -- Using target format's casting style\n",
    "    COALESCE(\n",
    "        lead(update_ts::DATE) OVER w, -- Get next record's date within the partition\n",
    "        '9999-12-31'::DATE           -- Default for the last record\n",
    "    ) AS enddate\n",
    "FROM\n",
    "    account a -- Using the original table name\n",
    "WINDOW w AS (\n",
    "    PARTITION BY accountid -- Partitioning by the key from the original query\n",
    "    ORDER BY update_ts     -- Ordering by the timestamp from the original query\n",
    " )\n",
    "),\n",
    "  account_cust_updates AS (\n",
    "  SELECT\n",
    "    a.* EXCLUDE (effectivedate, enddate, customerid),\n",
    "    c.sk_customerid,\n",
    "    if(\n",
    "      a.effectivedate < c.effectivedate,\n",
    "      c.effectivedate,\n",
    "      a.effectivedate\n",
    "    ) effectivedate,\n",
    "    if(a.enddate > c.enddate, c.enddate, a.enddate) enddate\n",
    "  FROM account_final a\n",
    "  FULL OUTER JOIN wh_db.DimCustomer c \n",
    "    ON a.customerid = c.customerid\n",
    "    AND c.enddate > a.effectivedate\n",
    "    AND c.effectivedate < a.enddate\n",
    "  WHERE a.effectivedate < a.enddate\n",
    ")\n",
    "SELECT\n",
    "    CAST(strftime(a.effectivedate, '%Y%m%d') || a.accountid AS BIGINT),\n",
    "    a.accountid,\n",
    "    b.sk_brokerid, \n",
    "    a.sk_customerid,\n",
    "    a.accountdesc,\n",
    "    a.TaxStatus,\n",
    "    a.status,\n",
    "    -- Using standard CASE instead of IF() for iscurrent calculation\n",
    "    CASE\n",
    "        WHEN a.enddate = '9999-12-31'::DATE THEN true\n",
    "        ELSE false\n",
    "    END AS iscurrent,\n",
    "    a.batchid,\n",
    "    a.effectivedate,\n",
    "    a.enddate\n",
    "FROM\n",
    "    account_cust_updates a\n",
    "JOIN\n",
    "    wh_db.DimBroker b ON a.brokerid = b.brokerid;\n",
    "\"\"\"\n",
    "\n",
    "con.sql(DimAccount)\n",
    "save_sql_to_file(DimAccount, \"wh_db.DimAccount\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a3b049a6fd641d8b4553711971ccc74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQL query successfully written to 'C:\\lopu-kg-test\\project\\src\\main\\sql_for_pipelines\\1_wh_db_stage.tradehistory.sql'.\n",
      "SQL query successfully written to 'C:\\lopu-kg-test\\project\\src\\main\\sql_for_pipelines\\2_wh_db_stage.tradehistory.sql'.\n"
     ]
    }
   ],
   "source": [
    "src_folder = 'src/data/Batch1'\n",
    "file_path = os.path.join(src_folder, \"Trade.txt\")\n",
    "\n",
    "# DimTrade\n",
    "tradetxt = f\"\"\" \n",
    "\n",
    "CREATE OR REPLACE TABLE wh_db_stage.tradetxt AS \n",
    "SELECT * from  read_csv('{file_path}', HEADER=FALSE, filename=false, all_varchar=true, delim='|',strict_mode=false , columns = {{\n",
    "    \"tradeid\": \"BIGINT\", \n",
    "    \"t_dts\": \"TIMESTAMP\",\n",
    "    \"status\": \"STRING\", \n",
    "    \"t_tt_id\": \"STRING\",\n",
    "    \"cashflag\": \"TINYINT\",\n",
    "    \"t_s_symb\": \"STRING\",\n",
    "    \"quantity\": \"INT\",\n",
    "    \"bidprice\": \"DOUBLE\",\n",
    "    \"t_ca_id\": \"BIGINT\",\n",
    "    \"executedby\": \"STRING\",\n",
    "    \"tradeprice\": \"DOUBLE\",\n",
    "    \"fee\": \"DOUBLE\",\n",
    "    \"commission\": \"DOUBLE\",\n",
    "    \"tax\": \"DOUBLE\"}});\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "src_folder = 'src/data/Batch1'\n",
    "file_path = os.path.join(src_folder, \"TradeHistory.txt\")\n",
    "tradehistory = f\"\"\" \n",
    "CREATE OR REPLACE TABLE wh_db_stage.tradehistory AS \n",
    "select * FROM read_csv_auto('{file_path}', HEADER=FALSE, filename=false, all_varchar=true, columns = {{\n",
    "    \"tradeid\": \"BIGINT\", --TH_T_ID\n",
    "    \"th_dts\": \"TIMESTAMP\", --TH_DTS\n",
    "    \"status\": \"STRING\"}}); --TH_ST_ID\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "con.sql(tradetxt)\n",
    "save_sql_to_file(tradetxt, \"wh_db_stage.tradehistory\")\n",
    "con.sql(tradehistory)\n",
    "save_sql_to_file(tradehistory, \"wh_db_stage.tradehistory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d54af4c38e74eecaa406a415ca7925f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQL query successfully written to 'C:\\lopu-kg-test\\project\\src\\main\\sql_for_pipelines\\1_wh_db.DimTrade.sql'.\n"
     ]
    }
   ],
   "source": [
    "DimTrade = f\"\"\" \n",
    "INSERT INTO wh_db.DimTrade\n",
    "WITH tradehistorical AS (\n",
    "select \n",
    "    a.tradeid,\n",
    "    --brokerid\n",
    "    CASE\n",
    "    \t\tWHEN b.status = 'SBMT' AND a.t_tt_id IN ( 'TMB', 'TMS' ) OR b.status = 'PNDG' THEN b.TH_DTS\n",
    "\t\t\tWHEN b.status IN ( 'CMPT', 'CNCL' ) THEN NULL\n",
    "\t\tEND AS SK_CreateDateID\n",
    "\t\t, CASE \n",
    "\t\t\tWHEN b.status = 'SBMT' AND a.t_tt_id IN ( 'TMB', 'TMS' ) OR b.status = 'PNDG' THEN b.TH_DTS\n",
    "\t\t\tWHEN b.status IN ( 'CMPT', 'CNCL' ) THEN NULL\n",
    "\t\tEND AS SK_CreateTimeID\n",
    "\t\t, CASE \n",
    "\t\t\tWHEN b.status = 'SBMT' AND a.t_tt_id IN ( 'TMB', 'TMS' ) OR b.status = 'PNDG' THEN NULL\n",
    "\t\t\tWHEN b.status IN ( 'CMPT', 'CNCL' ) THEN b.TH_DTS\n",
    "\t\tEND AS SK_CloseDateID\n",
    "\t\t, CASE \n",
    "\t\t\tWHEN b.status = 'SBMT' AND a.t_tt_id IN ( 'TMB', 'TMS' ) OR b.status = 'PNDG' THEN NULL\n",
    "\t\t\tWHEN b.status IN ( 'CMPT', 'CNCL' ) THEN b.TH_DTS\n",
    "    END AS SK_CloseTimeID,\n",
    "    c.st_name,\n",
    "    CASE t_tt_id\n",
    "      WHEN 'TMB' THEN 'Market Buy'\n",
    "      WHEN 'TMS' THEN 'Market Sell'\n",
    "      WHEN 'TSL' THEN 'Stop Loss'\n",
    "      WHEN 'TLS' THEN 'Limit Sell'\n",
    "      WHEN 'TLB' THEN 'Limit Buy'\n",
    "    ELSE NULL -- Or some default value if needed\n",
    "END AS type,\n",
    "  a.cashflag,\n",
    "  --ds.sk_securityid\n",
    "  --ds.sk_companyid\n",
    "  a.quantity,\n",
    "  a.bidprice,\n",
    "   -- sk_customerid\n",
    "  -- sk_accountid\n",
    "  a.executedby,\n",
    "  a.tradeprice,\n",
    "  a.fee,\n",
    "  a.commission,\n",
    "  a.tax,\n",
    "  1 batchid,\n",
    "  a.t_s_symb,\n",
    "  a.t_ca_id\n",
    "  from wh_db_stage.tradetxt a\n",
    "  join wh_db_stage.tradehistory b\n",
    "on a.tradeid = b.tradeid\n",
    "  join wh_db.StatusType c -- ainult üks praegu\n",
    "    ON a.status = c.st_id\n",
    ")\n",
    "select \n",
    "  trade.tradeid\n",
    "  ,da.sk_brokerid\n",
    "  ,CAST(strftime(trade.SK_CreateDateID, '%Y%m%d') || da.accountid || da.sk_brokerid AS BIGINT)\n",
    "  ,CAST(strftime(trade.SK_CreateTimeID, '%Y%m%d') || da.accountid || da.sk_brokerid AS BIGINT)\n",
    "  ,CAST(strftime(trade.SK_CloseDateID, '%Y%m%d') || da.accountid || da.sk_brokerid AS BIGINT)\n",
    "  ,CAST(strftime(trade.SK_CloseTimeID, '%Y%m%d') || da.accountid || da.sk_brokerid AS BIGINT)\n",
    "  ,trade.st_name\n",
    "  ,trade.type\n",
    "  ,trade.cashflag\n",
    "  ,ds.sk_securityid\n",
    "  ,ds.sk_companyid\n",
    "  ,trade.quantity\n",
    "  ,trade.bidprice\n",
    "  ,da.sk_customerid\n",
    "  ,da.sk_accountid\n",
    "  ,trade.executedby\n",
    "  ,trade.tradeprice\n",
    "  ,trade.fee\n",
    "  ,trade.commission\n",
    "  ,trade.tax\n",
    "  ,1 batchid\n",
    "  \n",
    "from tradehistorical trade\n",
    "JOIN wh_db.DimSecurity ds\n",
    "  ON \n",
    "    ds.symbol = trade.t_s_symb\n",
    "    AND SK_CreateDateID::DATE >= ds.effectivedate \n",
    "    AND SK_CreateDateID::DATE < ds.enddate\n",
    "JOIN wh_db.DimAccount da\n",
    "  ON \n",
    "    trade.t_ca_id = da.accountid \n",
    "    AND SK_CreateDateID::DATE >= da.effectivedate \n",
    "    AND SK_CreateDateID::DATE < da.enddate;\n",
    "        \"\"\"\n",
    "\n",
    "con.sql(DimTrade)\n",
    "save_sql_to_file(DimTrade, \"wh_db.DimTrade\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a129c1d2c5464f2dbe8cffb06109645a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQL query successfully written to 'C:\\lopu-kg-test\\project\\src\\main\\sql_for_pipelines\\1_wh_db.FactCashBalances.sql'.\n"
     ]
    }
   ],
   "source": [
    "# FactCashBalances\n",
    "src_folder = 'src/data/Batch1'\n",
    "file_path = os.path.join(src_folder, \"CashTransaction.txt\")\n",
    "FactCashBalances = f\"\"\" \n",
    "INSERT INTO wh_db.FactCashBalances\n",
    "WITH historical AS (\n",
    "    SELECT\n",
    "        accountid,\n",
    "        ct_dts::DATE AS datevalue,\n",
    "        SUM(ct_amt) AS account_daily_total,\n",
    "        1 batchid\n",
    "    FROM read_csv(\n",
    "        '{file_path}',\n",
    "        HEADER=FALSE,\n",
    "        columns={{'accountid': 'BIGINT', 'ct_dts': 'TIMESTAMP', 'ct_amt': 'DOUBLE', 'ct_name': 'VARCHAR'}}\n",
    "    )\n",
    "    GROUP BY ALL\n",
    "  )\n",
    "SELECT\n",
    "    a.sk_customerid,\n",
    "    a.sk_accountid,\n",
    "    CAST(STRFTIME(datevalue, '%Y%m%d') AS BIGINT) AS sk_dateid,\n",
    "    SUM(account_daily_total) OVER (PARTITION BY c.accountid ORDER BY datevalue) AS cash,\n",
    "    c.batchid\n",
    "FROM historical c\n",
    "JOIN wh_db.DimAccount a\n",
    "    ON c.accountid = a.accountid\n",
    "    AND c.datevalue >= a.effectivedate\n",
    "    AND c.datevalue < a.enddate;\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "con.sql(FactCashBalances)\n",
    "save_sql_to_file(FactCashBalances, \"wh_db.FactCashBalances\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQL query successfully written to 'C:\\lopu-kg-test\\project\\src\\main\\sql_for_pipelines\\1_wh_db.FactHoldings.sql'.\n"
     ]
    }
   ],
   "source": [
    "# replace filename\n",
    "FactHoldings = f\"\"\" \n",
    "INSERT INTO wh_db.FactHoldings\n",
    "WITH Holdings AS (\n",
    "    SELECT\n",
    "        *,\n",
    "        1 AS batchid\n",
    "    FROM read_csv(\n",
    "        'src/data/Batch1\\\\HoldingHistory.txt',\n",
    "        HEADER=FALSE,\n",
    "        columns={{'hh_h_t_id': 'INTEGER', 'hh_t_id': 'INTEGER', 'hh_before_qty': 'INTEGER', 'hh_after_qty': 'INTEGER'}}\n",
    "    )\n",
    ")\n",
    "SELECT\n",
    "  hh_h_t_id tradeid,\n",
    "  hh_t_id currenttradeid,\n",
    "  sk_customerid,\n",
    "  sk_accountid,\n",
    "  sk_securityid,\n",
    "  sk_companyid,\n",
    "  sk_closedateid sk_dateid,\n",
    "  sk_closetimeid sk_timeid,\n",
    "  tradeprice currentprice,\n",
    "  hh_after_qty currentholding,\n",
    "  h.batchid\n",
    "FROM Holdings h\n",
    "  JOIN wh_db.DimTrade dt \n",
    "    ON tradeid = hh_t_id;\n",
    "     \"\"\"\n",
    "con.sql(FactHoldings)\n",
    "save_sql_to_file(FactHoldings, \"wh_db.FactHoldings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0619049c804b4a97990c4caf7188385f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQL query successfully written to 'C:\\lopu-kg-test\\project\\src\\main\\sql_for_pipelines\\1_wh_db.FactWatches.sql'.\n"
     ]
    }
   ],
   "source": [
    "#replace table name\n",
    "FactWatches = f\"\"\" \n",
    "INSERT INTO wh_db.FactWatches\n",
    "WITH watchhistory AS (\n",
    "    SELECT\n",
    "        *,\n",
    "        1 AS batchid\n",
    "    FROM read_csv(\n",
    "        'src/data/Batch1\\\\WatchHistory.txt',\n",
    "        HEADER=FALSE,\n",
    "        columns={{'w_c_id': 'BIGINT', 'w_s_symb': 'VARCHAR', 'w_dts': 'TIMESTAMP', 'w_action': 'VARCHAR'}}\n",
    "    )\n",
    "),\n",
    "watches AS (\n",
    "    SELECT\n",
    "        wh.w_c_id AS customerid,\n",
    "        wh.w_s_symb AS symbol,\n",
    "        MIN(w_dts)::DATE AS dateplaced,\n",
    "        CASE WHEN w_action = 'CNCL' THEN w_dts ELSE NULL END::DATE AS dateremoved,\n",
    "        MIN(batchid) AS batchid\n",
    "    FROM watchhistory wh\n",
    "    GROUP BY ALL\n",
    ")\n",
    "select\n",
    "  c.sk_customerid sk_customerid,\n",
    "  s.sk_securityid sk_securityid,\n",
    "  CAST(strftime(dateplaced, '%Y%m%d') AS BIGINT)  sk_dateid_dateplaced,\n",
    "  CAST(strftime(dateremoved, '%Y%m%d') AS BIGINT) sk_dateid_dateremoved,\n",
    "  wh.batchid \n",
    "from watches wh\n",
    "JOIN wh_db.DimSecurity s \n",
    "  ON \n",
    "    s.symbol = wh.symbol\n",
    "    AND wh.dateplaced >= s.effectivedate \n",
    "    AND wh.dateplaced < s.enddate\n",
    "JOIN wh_db.DimCustomer c \n",
    "  ON\n",
    "    wh.customerid = c.customerid\n",
    "    AND wh.dateplaced >= c.effectivedate \n",
    "    AND wh.dateplaced < c.enddate;\n",
    "\"\"\"\n",
    "con.sql(FactWatches)\n",
    "save_sql_to_file(FactWatches, \"wh_db.FactWatches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8639478e2e8c4516a53e5093d30f8045",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQL query successfully written to 'C:\\lopu-kg-test\\project\\src\\main\\sql_for_pipelines\\1_wh_db.Financial.sql'.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "Financial = f\"\"\" \n",
    "INSERT INTO wh_db.Financial\n",
    "WITH finwire_parsed AS (\n",
    "    -- Parse the fixed-width data and extract relevant fields including conditional id/cname\n",
    "    SELECT\n",
    "        CAST(SUBSTRING(value FROM 1 FOR 4) AS INTEGER) AS fi_year,\n",
    "        CAST(SUBSTRING(value FROM 5 FOR 1) AS INTEGER) AS fi_qtr,\n",
    "        -- Explicitly cast strptime result to DATE if effectivedate/enddate are DATEs\n",
    "        strptime(SUBSTRING(value FROM 6 FOR 8), '%Y%m%d')::DATE AS fi_qtr_start_date,\n",
    "        CAST(SUBSTRING(value FROM 22 FOR 17) AS DOUBLE) AS fi_revenue,\n",
    "        CAST(SUBSTRING(value FROM 39 FOR 17) AS DOUBLE) AS fi_net_earn,\n",
    "        CAST(SUBSTRING(value FROM 56 FOR 12) AS DOUBLE) AS fi_basic_eps,\n",
    "        CAST(SUBSTRING(value FROM 68 FOR 12) AS DOUBLE) AS fi_dilut_eps,\n",
    "        CAST(SUBSTRING(value FROM 80 FOR 12) AS DOUBLE) AS fi_margin,\n",
    "        CAST(SUBSTRING(value FROM 92 FOR 17) AS DOUBLE) AS fi_inventory,\n",
    "        CAST(SUBSTRING(value FROM 109 FOR 17) AS DOUBLE) AS fi_assets,\n",
    "        CAST(SUBSTRING(value FROM 126 FOR 17) AS DOUBLE) AS fi_liability,\n",
    "        CAST(SUBSTRING(value FROM 143 FOR 13) AS BIGINT) AS fi_out_basic,\n",
    "        CAST(SUBSTRING(value FROM 156 FOR 13) AS BIGINT) AS fi_out_dilut,\n",
    "        -- Conditionally extract ID (as TEXT) or Name\n",
    "        -- Ensure id and cname columns are mutually exclusive (one is NULL if other is not)\n",
    "        CASE\n",
    "            WHEN regexp_matches(SUBSTRING(value FROM -10), '^[0-9]+$')\n",
    "            -- Remove leading zeros and trim; result is TEXT\n",
    "            THEN trim(regexp_replace(SUBSTRING(value FROM -10), '^0+', ''))\n",
    "            ELSE NULL\n",
    "        END AS company_id_text,\n",
    "        CASE\n",
    "            WHEN NOT regexp_matches(SUBSTRING(value FROM -10), '^[0-9]+$')\n",
    "            THEN trim(SUBSTRING(value FROM -60))\n",
    "            ELSE NULL\n",
    "        END AS company_name,\n",
    "        -- Keep recdate for joining condition\n",
    "        recdate\n",
    "    FROM wh_db_stage.FinWire\n",
    "    -- Filter record types early in the CTE\n",
    "    WHERE rectype IN ('FIN_COMPANYID', 'FIN_NAME')\n",
    ")\n",
    "SELECT\n",
    "    -- Select the SK from the successfully joined DimCompany record\n",
    "    dc.sk_companyid,\n",
    "    -- Select all parsed financial columns, excluding intermediate fields\n",
    "    fp.* EXCLUDE (company_id_text, company_name, recdate)\n",
    "FROM finwire_parsed AS fp\n",
    "-- Use a single INNER JOIN (or LEFT JOIN if you need un-matched finwire rows)\n",
    "JOIN wh_db.DimCompany AS dc\n",
    "    -- Apply the date range filter first (can help with partitioning/pruning)\n",
    "    ON fp.recdate >= dc.effectivedate\n",
    "   AND fp.recdate < dc.enddate\n",
    "    -- Apply the conditional join logic: match EITHER id OR name\n",
    "   AND (\n",
    "        (fp.company_id_text IS NOT NULL AND fp.company_id_text = dc.companyid::TEXT) -- Cast dc.companyid to TEXT if needed\n",
    "        OR\n",
    "        (fp.company_name IS NOT NULL AND fp.company_name = dc.name)\n",
    "   );\n",
    "\"\"\"\n",
    "\n",
    "con.sql(Financial)\n",
    "save_sql_to_file(Financial, \"wh_db.Financial\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQL query successfully written to 'C:\\lopu-kg-test\\project\\src\\main\\sql_for_pipelines\\1_wh_db.Prospect.sql'.\n"
     ]
    }
   ],
   "source": [
    "# Prospect\n",
    "Prospect = \"\"\"\n",
    "INSERT INTO wh_db.Prospect\n",
    "WITH cust AS (\n",
    "    SELECT\n",
    "        lastname,\n",
    "        firstname,\n",
    "        addressline1,\n",
    "        addressline2,\n",
    "        postalcode\n",
    "    FROM wh_db.DimCustomer\n",
    "    WHERE iscurrent = 'Y'\n",
    ")\n",
    "SELECT\n",
    "    p.agencyid,\n",
    "    CAST(STRFTIME(recdate.batchdate, '%Y%m%d') AS BIGINT) AS sk_recorddateid,\n",
    "    CAST(STRFTIME(origdate.batchdate, '%Y%m%d') AS BIGINT) AS sk_updatedateid,\n",
    "    p.batchid,\n",
    "    CASE WHEN c.LastName IS NOT NULL THEN TRUE ELSE FALSE END AS iscustomer,\n",
    "    p.lastname,\n",
    "    p.firstname,\n",
    "    p.middleinitial,\n",
    "    p.gender,\n",
    "    p.addressline1,\n",
    "    p.addressline2,\n",
    "    p.postalcode,\n",
    "    city,\n",
    "    state,\n",
    "    country,\n",
    "    phone,\n",
    "    income,\n",
    "    numbercars,\n",
    "    numberchildren,\n",
    "    maritalstatus,\n",
    "    age,\n",
    "    creditrating,\n",
    "    ownorrentflag,\n",
    "    employer,\n",
    "    numbercreditcards,\n",
    "    networth,\n",
    "    marketingnameplate\n",
    "FROM wh_db_stage.ProspectIncremental p\n",
    "JOIN wh_db.BatchDate recdate\n",
    "    ON p.recordbatchid = recdate.batchid\n",
    "JOIN wh_db.BatchDate origdate\n",
    "    ON p.batchid = origdate.batchid\n",
    "LEFT JOIN cust c\n",
    "    ON\n",
    "         UPPER(p.LastName) = UPPER(c.lastname)\n",
    "        AND UPPER(p.FirstName) = UPPER(c.firstname)\n",
    "        AND UPPER(p.AddressLine1) = UPPER(c.addressline1)\n",
    "        AND UPPER(COALESCE(p.addressline2, '')) = UPPER(COALESCE(c.addressline2, ''))\n",
    "        AND UPPER(p.PostalCode) = UPPER(c.postalcode)\n",
    "         ;\n",
    "\"\"\"\n",
    "\n",
    "con.sql(Prospect)\n",
    "save_sql_to_file(Prospect, \"wh_db.Prospect\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d12732f9f0445139b699736528275d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "┌──────────────────────────────────────┐\n",
       "│                result                │\n",
       "│               varchar                │\n",
       "├──────────────────────────────────────┤\n",
       "│ UI started at http://localhost:4213/ │\n",
       "└──────────────────────────────────────┘"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con_path = r\"initial_db.duckdb\"\n",
    "con = duckdb.connect(con_path)\n",
    "con.sql(\"CALL start_ui();\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cdc_flag                 object\n",
      "cdc_dsn                   int64\n",
      "customerid                int64\n",
      "taxid                    object\n",
      "status                   object\n",
      "lastname                 object\n",
      "firstname                object\n",
      "middleinitial            object\n",
      "gender                   object\n",
      "tier                       int8\n",
      "dob              datetime64[us]\n",
      "addressline1             object\n",
      "addressline2             object\n",
      "postalcode               object\n",
      "city                     object\n",
      "stateprov                object\n",
      "country                  object\n",
      "c_ctry_1                 object\n",
      "c_area_1                 object\n",
      "c_local_1                object\n",
      "c_ext_1                  object\n",
      "c_ctry_2                 object\n",
      "c_area_2                 object\n",
      "c_local_2                object\n",
      "c_ext_2                  object\n",
      "c_ctry_3                 object\n",
      "c_area_3                 object\n",
      "c_local_3                object\n",
      "c_ext_3                  object\n",
      "email1                   object\n",
      "email2                   object\n",
      "lcl_tx_id                object\n",
      "nat_tx_id                object\n",
      "dtype: object\n",
      "  cdc_flag  cdc_dsn  customerid        taxid status   lastname firstname  \\\n",
      "0        U    10810        6737  061-42-7627   ACTV  Provencal     Laten   \n",
      "1        U    10811        2440  259-81-3662   ACTV      Leuty    Nguyet   \n",
      "2        U    10812        3701  287-28-9942   INAC     Sehgal   Mirabel   \n",
      "3        I    10813        7800  628-43-4159   ACTV  Osterhout    Blaine   \n",
      "4        I    10814        7801  909-06-8298   ACTV   Vendette     Joann   \n",
      "\n",
      "  middleinitial gender  tier  ... c_local_2 c_ext_2 c_ctry_3 c_area_3  \\\n",
      "0             J   None     2  ...  066-0546    None     None     None   \n",
      "1             H   None     3  ...  448-7075    None     None     None   \n",
      "2          None      M     3  ...  121-1224   37951     None     None   \n",
      "3          None   None     3  ...  824-9324    None     None     None   \n",
      "4          None      f     1  ...  650-1923    None     None     None   \n",
      "\n",
      "  c_local_3 c_ext_3                             email1  \\\n",
      "0      None    None     Laten.J.Provencal@hushmail.com   \n",
      "1  519-6150    None  Nguyet.H.Leuty@ProtectAnimals.com   \n",
      "2      None    None       Mirabel.Sehgal@spamavert.com   \n",
      "3      None    None      Blaine.Osterhout@hushmail.com   \n",
      "4      None    None           Joann.Vendette@gawab.com   \n",
      "\n",
      "                            email2 lcl_tx_id nat_tx_id  \n",
      "0                             None       ON3       AR5  \n",
      "1                             None       NS1       DE1  \n",
      "2                             None       KS3       PE8  \n",
      "3  Blaine.Osterhout@snail-mail.net       KY5       SK8  \n",
      "4                             None       MO7       NT1  \n",
      "\n",
      "[5 rows x 33 columns]\n"
     ]
    }
   ],
   "source": [
    "# Customer hakkab alles batch2-st?\n",
    "\n",
    "src_folder = 'src/data/Batch2'\n",
    "file_path = os.path.join(src_folder, \"Customer.txt\")\n",
    "batch_number = int(''.join(filter(str.isdigit, os.path.basename(src_folder))))\n",
    "\n",
    "columns = {\n",
    "    \"cdc_flag\": \"VARCHAR\",\n",
    "    \"cdc_dsn\": \"BIGINT\",\n",
    "    \"customerid\": \"BIGINT\",\n",
    "    \"taxid\": \"VARCHAR\",\n",
    "    \"status\": \"VARCHAR\",\n",
    "    \"lastname\": \"VARCHAR\",\n",
    "    \"firstname\": \"VARCHAR\",\n",
    "    \"middleinitial\": \"VARCHAR\",\n",
    "    \"gender\": \"VARCHAR\",\n",
    "    \"tier\": \"TINYINT\",\n",
    "    \"dob\": \"DATE\",\n",
    "    \"addressline1\": \"VARCHAR\",\n",
    "    \"addressline2\": \"VARCHAR\",\n",
    "    \"postalcode\": \"VARCHAR\",\n",
    "    \"city\": \"VARCHAR\",\n",
    "    \"stateprov\": \"VARCHAR\",\n",
    "    \"country\": \"VARCHAR\",\n",
    "    \"c_ctry_1\": \"VARCHAR\",\n",
    "    \"c_area_1\": \"VARCHAR\",\n",
    "    \"c_local_1\": \"VARCHAR\",\n",
    "    \"c_ext_1\": \"VARCHAR\",\n",
    "    \"c_ctry_2\": \"VARCHAR\",\n",
    "    \"c_area_2\": \"VARCHAR\",\n",
    "    \"c_local_2\": \"VARCHAR\",\n",
    "    \"c_ext_2\": \"VARCHAR\",\n",
    "    \"c_ctry_3\": \"VARCHAR\",\n",
    "    \"c_area_3\": \"VARCHAR\",\n",
    "    \"c_local_3\": \"VARCHAR\",\n",
    "    \"c_ext_3\": \"VARCHAR\",\n",
    "    \"email1\": \"VARCHAR\",\n",
    "    \"email2\": \"VARCHAR\",\n",
    "    \"lcl_tx_id\": \"VARCHAR\",\n",
    "    \"nat_tx_id\": \"VARCHAR\"\n",
    "}\n",
    "\n",
    "df = con.sql(f\"SELECT * FROM read_csv('{file_path}', columns = $columns)\", params={\"columns\": columns}).df()\n",
    "\n",
    "print(df.dtypes)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# peale batch ingestionit täita ka wh_db.BatchDate\n",
    "\n",
    "src_folder = 'src/data/Batch1'\n",
    "file_path = os.path.join(src_folder, \"BatchDate.txt\")\n",
    "batch_number = int(''.join(filter(str.isdigit, os.path.basename(src_folder))))\n",
    "\n",
    "con.sql(f\"\"\"\n",
    "INSERT INTO wh_db.BatchDate\n",
    "SELECT batchdate::DATE,\n",
    "    {batch_number} AS batchid \n",
    "    FROM read_csv_auto('{file_path}', columns={{\n",
    "    \"batchdate\": \"DATE\"\n",
    "}}, header=False);\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<duckdb.duckdb.DuckDBPyConnection at 0x25ea65385b0>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "template_name = \"llm_prompt_for_column_level_lineage_easy\"\n",
    "llm_answers_dir = f\"C:\\lopu-kg-test\\project\\src\\LLM_answers/{template_name}\"\n",
    "os.makedirs(llm_answers_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>agencyid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lastname</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>firstname</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>middleinitial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gender</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>addressline1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>addressline2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>postalcode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>city</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>state</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>country</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>phone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>income</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>numbercars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>numberchildren</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>maritalstatus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>age</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>creditrating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ownorrentflag</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>employer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>numbercreditcards</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>networth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>marketingnameplate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>recordbatchid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>batchid</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           column_name\n",
       "0             agencyid\n",
       "1             lastname\n",
       "2            firstname\n",
       "3        middleinitial\n",
       "4               gender\n",
       "5         addressline1\n",
       "6         addressline2\n",
       "7           postalcode\n",
       "8                 city\n",
       "9                state\n",
       "10             country\n",
       "11               phone\n",
       "12              income\n",
       "13          numbercars\n",
       "14      numberchildren\n",
       "15       maritalstatus\n",
       "16                 age\n",
       "17        creditrating\n",
       "18       ownorrentflag\n",
       "19            employer\n",
       "20   numbercreditcards\n",
       "21            networth\n",
       "22  marketingnameplate\n",
       "23       recordbatchid\n",
       "24             batchid"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con = duckdb.connect(database=db_path)\n",
    "#con.sql(\"select * from sqlite_temp_schema \")\n",
    "con.sql(\"select column_name from information_schema.columns where table_name = 'ProspectIncremental'\").df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    COLUMN_COMMENT\n",
      "0             None\n",
      "1             None\n",
      "2             None\n",
      "3             None\n",
      "4             None\n",
      "..             ...\n",
      "421           None\n",
      "422           None\n",
      "423           None\n",
      "424           None\n",
      "425           None\n",
      "\n",
      "[426 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "print(con.execute(\"select table_name, COLUMN_COMMENT from information_schema.columns\").fetchdf())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Information schemast tabelid ja skeemad sisse\n",
    "2. Data pipelineid ja nende logimine, et pärast võrrelda LLM-i tulemusi päris tulemustega.\n",
    "3. \n",
    "\n",
    "Küsimused:\n",
    "1. Kas a la risk metric summa on alati numbriline väärtus?\n",
    "2. Meil oleks vaja luua kontroll, et statustype ei tohi olla D, milliseid samme peaksime muutma?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
